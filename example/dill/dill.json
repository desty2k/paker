{
    "dill": {
        "type": "package",
        "extension": "py",
        "code": "#!/usr/bin/env python\n#\n# Author: Mike McKerns (mmckerns @caltech and @uqfoundation)\n# Copyright (c) 2008-2016 California Institute of Technology.\n# Copyright (c) 2016-2020 The Uncertainty Quantification Foundation.\n# License: 3-clause BSD.  The full license text is available at:\n#  - https://github.com/uqfoundation/dill/blob/master/LICENSE\n\n# get version numbers, license, and long description\ntry:\n    from .info import this_version as __version__\n    from .info import readme as __doc__, license as __license__\nexcept ImportError:\n    msg = \"\"\"First run 'python setup.py build' to build dill.\"\"\"\n    raise ImportError(msg)\n\n__author__ = 'Mike McKerns'\n\n__doc__ = \"\"\"\n\"\"\" + __doc__\n\n__license__ = \"\"\"\n\"\"\" + __license__\n\nfrom ._dill import dump, dumps, load, loads, dump_session, load_session, \\\n    Pickler, Unpickler, register, copy, pickle, pickles, check, \\\n    HIGHEST_PROTOCOL, DEFAULT_PROTOCOL, PicklingError, UnpicklingError, \\\n    HANDLE_FMODE, CONTENTS_FMODE, FILE_FMODE\nfrom . import source, temp, detect\n\n# get global settings\nfrom .settings import settings\n\n# make sure \"trace\" is turned off\ndetect.trace(False)\n\ntry:\n    from importlib import reload\nexcept ImportError:\n    try:\n        from imp import reload\n    except ImportError:\n        pass\n\n# put the objects in order, if possible\ntry:\n    from collections import OrderedDict as odict\nexcept ImportError:\n    try:\n        from ordereddict import OrderedDict as odict\n    except ImportError:\n        odict = dict\nobjects = odict()\n# local import of dill._objects\n#from . import _objects\n#objects.update(_objects.succeeds)\n#del _objects\n\n# local import of dill.objtypes\nfrom . import objtypes as types\n\ndef load_types(pickleable=True, unpickleable=True):\n    \"\"\"load pickleable and/or unpickleable types to ``dill.types``\n\n    ``dill.types`` is meant to mimic the ``types`` module, providing a\n    registry of object types.  By default, the module is empty (for import\n    speed purposes). Use the ``load_types`` function to load selected object\n    types to the ``dill.types`` module.\n\n    Args:\n        pickleable (bool, default=True): if True, load pickleable types.\n        unpickleable (bool, default=True): if True, load unpickleable types.\n\n    Returns:\n        None\n    \"\"\"\n    # local import of dill.objects\n    from . import _objects\n    if pickleable:\n        objects.update(_objects.succeeds)\n    else:\n        [objects.pop(obj,None) for obj in _objects.succeeds]\n    if unpickleable:\n        objects.update(_objects.failures)\n    else:\n        [objects.pop(obj,None) for obj in _objects.failures]\n    objects.update(_objects.registered)\n    del _objects\n    # reset contents of types to 'empty'\n    [types.__dict__.pop(obj) for obj in list(types.__dict__.keys()) \\\n                             if obj.find('Type') != -1]\n    # add corresponding types from objects to types\n    reload(types)\n\ndef extend(use_dill=True):\n    '''add (or remove) dill types to/from the pickle registry\n\n    by default, ``dill`` populates its types to ``pickle.Pickler.dispatch``.\n    Thus, all ``dill`` types are available upon calling ``'import pickle'``.\n    To drop all ``dill`` types from the ``pickle`` dispatch, *use_dill=False*.\n\n    Args:\n        use_dill (bool, default=True): if True, extend the dispatch table.\n\n    Returns:\n        None\n    '''\n    from ._dill import _revert_extension, _extend\n    if use_dill: _extend()\n    else: _revert_extension()\n    return\n\nextend()\n\ndef license():\n    \"\"\"print license\"\"\"\n    print (__license__)\n    return\n\ndef citation():\n    \"\"\"print citation\"\"\"\n    print (__doc__[-485:-115])\n    return\n\ndel odict\n\n# end of file\n",
        "modules": {
            "__diff": {
                "type": "module",
                "extension": "py",
                "code": "#!/usr/bin/env python\n#\n# Author: Mike McKerns (mmckerns @caltech and @uqfoundation)\n# Copyright (c) 2008-2016 California Institute of Technology.\n# Copyright (c) 2016-2020 The Uncertainty Quantification Foundation.\n# License: 3-clause BSD.  The full license text is available at:\n#  - https://github.com/uqfoundation/dill/blob/master/LICENSE\n\n\"\"\"\nModule to show if an object has changed since it was memorised\n\"\"\"\n\nimport os\nimport sys\nimport types\ntry:\n    import numpy\n    HAS_NUMPY = True\nexcept:\n    HAS_NUMPY = False\ntry:\n    import builtins\nexcept ImportError:\n    import __builtin__ as builtins\n\n# pypy doesn't use reference counting\ngetrefcount = getattr(sys, 'getrefcount', lambda x:0)\n\n# memo of objects indexed by id to a tuple (attributes, sequence items)\n# attributes is a dict indexed by attribute name to attribute id\n# sequence items is either a list of ids, of a dictionary of keys to ids\nmemo = {}\nid_to_obj = {}\n# types that cannot have changing attributes\nbuiltins_types = set((str, list, dict, set, frozenset, int))\ndont_memo = set(id(i) for i in (memo, sys.modules, sys.path_importer_cache,\n             os.environ, id_to_obj))\n\n\ndef get_attrs(obj):\n    \"\"\"\n    Gets all the attributes of an object though its __dict__ or return None\n    \"\"\"\n    if type(obj) in builtins_types \\\n       or type(obj) is type and obj in builtins_types:\n        return\n    try:\n        return obj.__dict__\n    except:\n        return\n\n\ndef get_seq(obj, cache={str: False, frozenset: False, list: True, set: True,\n                        dict: True, tuple: True, type: False,\n                        types.ModuleType: False, types.FunctionType: False,\n                        types.BuiltinFunctionType: False}):\n    \"\"\"\n    Gets all the items in a sequence or return None\n    \"\"\"\n    try:\n        o_type = obj.__class__\n    except AttributeError:\n        o_type = type(obj)\n    hsattr = hasattr\n    if o_type in cache:\n        if cache[o_type]:\n            if hsattr(obj, \"copy\"):\n                return obj.copy()\n            return obj\n    elif HAS_NUMPY and o_type in (numpy.ndarray, numpy.ma.core.MaskedConstant):\n        if obj.shape and obj.size:\n            return obj\n        else:\n            return []\n    elif hsattr(obj, \"__contains__\") and hsattr(obj, \"__iter__\") \\\n       and hsattr(obj, \"__len__\") and hsattr(o_type, \"__contains__\") \\\n       and hsattr(o_type, \"__iter__\") and hsattr(o_type, \"__len__\"):\n        cache[o_type] = True\n        if hsattr(obj, \"copy\"):\n            return obj.copy()\n        return obj\n    else:\n        cache[o_type] = False\n        return None\n\n\ndef memorise(obj, force=False):\n    \"\"\"\n    Adds an object to the memo, and recursively adds all the objects\n    attributes, and if it is a container, its items. Use force=True to update\n    an object already in the memo. Updating is not recursively done.\n    \"\"\"\n    obj_id = id(obj)\n    if obj_id in memo and not force or obj_id in dont_memo:\n        return\n    id_ = id\n    g = get_attrs(obj)\n    if g is None:\n        attrs_id = None\n    else:\n        attrs_id = dict((key,id_(value)) for key, value in g.items())\n\n    s = get_seq(obj)\n    if s is None:\n        seq_id = None\n    elif hasattr(s, \"items\"):\n        seq_id = dict((id_(key),id_(value)) for key, value in s.items())\n    elif not hasattr(s, \"__len__\"): #XXX: avoid TypeError from unexpected case\n        seq_id = None\n    else:\n        seq_id = [id_(i) for i in s]\n\n    memo[obj_id] = attrs_id, seq_id\n    id_to_obj[obj_id] = obj\n    mem = memorise\n    if g is not None:\n        [mem(value) for key, value in g.items()]\n\n    if s is not None:\n        if hasattr(s, \"items\"):\n            [(mem(key), mem(item))\n             for key, item in s.items()]\n        else:\n            if hasattr(s, '__len__'):\n                [mem(item) for item in s]\n            else: mem(s)\n\n\ndef release_gone():\n    itop, mp, src = id_to_obj.pop, memo.pop, getrefcount\n    [(itop(id_), mp(id_)) for id_, obj in list(id_to_obj.items())\n     if src(obj) < 4] #XXX: correct for pypy?\n\n\ndef whats_changed(obj, seen=None, simple=False, first=True):\n    \"\"\"\n    Check an object against the memo. Returns a list in the form\n    (attribute changes, container changed). Attribute changes is a dict of\n    attribute name to attribute value. container changed is a boolean.\n    If simple is true, just returns a boolean. None for either item means\n    that it has not been checked yet\n    \"\"\"\n    # Special cases\n    if first:\n        # ignore the _ variable, which only appears in interactive sessions\n        if \"_\" in builtins.__dict__:\n            del builtins._\n        if seen is None:\n            seen = {}\n\n    obj_id = id(obj)\n\n    if obj_id in seen:\n        if simple:\n            return any(seen[obj_id])\n        return seen[obj_id]\n\n    # Safety checks\n    if obj_id in dont_memo:\n        seen[obj_id] = [{}, False]\n        if simple:\n            return False\n        return seen[obj_id]\n    elif obj_id not in memo:\n        if simple:\n            return True\n        else:\n            raise RuntimeError(\"Object not memorised \" + str(obj))\n\n    seen[obj_id] = ({}, False)\n\n    chngd = whats_changed\n    id_ = id\n\n    # compare attributes\n    attrs = get_attrs(obj)\n    if attrs is None:\n        changed = {}\n    else:\n        obj_attrs = memo[obj_id][0]\n        obj_get = obj_attrs.get\n        changed = dict((key,None) for key in obj_attrs if key not in attrs)\n        for key, o in attrs.items():\n            if id_(o) != obj_get(key, None) or chngd(o, seen, True, False):\n                changed[key] = o\n\n    # compare sequence\n    items = get_seq(obj)\n    seq_diff = False\n    if (items is not None) and (hasattr(items, '__len__')):\n        obj_seq = memo[obj_id][1]\n        if (len(items) != len(obj_seq)):\n            seq_diff = True\n        elif hasattr(obj, \"items\"):  # dict type obj\n            obj_get = obj_seq.get\n            for key, item in items.items():\n                if id_(item) != obj_get(id_(key)) \\\n                   or chngd(key, seen, True, False) \\\n                   or chngd(item, seen, True, False):\n                    seq_diff = True\n                    break\n        else:\n            for i, j in zip(items, obj_seq):  # list type obj\n                if id_(i) != j or chngd(i, seen, True, False):\n                    seq_diff = True\n                    break\n    seen[obj_id] = changed, seq_diff\n    if simple:\n        return changed or seq_diff\n    return changed, seq_diff\n\n\ndef has_changed(*args, **kwds):\n    kwds['simple'] = True  # ignore simple if passed in\n    return whats_changed(*args, **kwds)\n\n__import__ = __import__\n\n\ndef _imp(*args, **kwds):\n    \"\"\"\n    Replaces the default __import__, to allow a module to be memorised\n    before the user can change it\n    \"\"\"\n    before = set(sys.modules.keys())\n    mod = __import__(*args, **kwds)\n    after = set(sys.modules.keys()).difference(before)\n    for m in after:\n        memorise(sys.modules[m])\n    return mod\n\nbuiltins.__import__ = _imp\nif hasattr(builtins, \"_\"):\n    del builtins._\n\n# memorise all already imported modules. This implies that this must be\n# imported first for any changes to be recorded\nfor mod in sys.modules.values():\n    memorise(mod)\nrelease_gone()\n"
            },
            "_dill": {
                "type": "module",
                "extension": "py",
                "code": "# -*- coding: utf-8 -*-\n#\n# Author: Mike McKerns (mmckerns @caltech and @uqfoundation)\n# Copyright (c) 2008-2015 California Institute of Technology.\n# Copyright (c) 2016-2020 The Uncertainty Quantification Foundation.\n# License: 3-clause BSD.  The full license text is available at:\n#  - https://github.com/uqfoundation/dill/blob/master/LICENSE\n\"\"\"\ndill: a utility for serialization of python objects\n\nBased on code written by Oren Tirosh and Armin Ronacher.\nExtended to a (near) full set of the builtin types (in types module),\nand coded to the pickle interface, by <mmckerns@caltech.edu>.\nInitial port to python3 by Jonathan Dobson, continued by mmckerns.\nTest against \"all\" python types (Std. Lib. CH 1-15 @ 2.7) by mmckerns.\nTest against CH16+ Std. Lib. ... TBD.\n\"\"\"\n__all__ = ['dump','dumps','load','loads','dump_session','load_session',\n           'Pickler','Unpickler','register','copy','pickle','pickles',\n           'check','HIGHEST_PROTOCOL','DEFAULT_PROTOCOL','PicklingError',\n           'UnpicklingError','HANDLE_FMODE','CONTENTS_FMODE','FILE_FMODE']\n\nimport logging\nlog = logging.getLogger(\"dill\")\nlog.addHandler(logging.StreamHandler())\ndef _trace(boolean):\n    \"\"\"print a trace through the stack when pickling; useful for debugging\"\"\"\n    if boolean: log.setLevel(logging.INFO)\n    else: log.setLevel(logging.WARN)\n    return\n\nstack = dict()  # record of 'recursion-sensitive' pickled objects\n\nimport os\nimport sys\ndiff = None\n_use_diff = False\nPY3 = (sys.hexversion >= 0x3000000)\n# OLDER: 3.0 <= x < 3.4 *OR* x < 2.7.10  #NOTE: guessing relevant versions\nOLDER = (PY3 and sys.hexversion < 0x3040000) or (sys.hexversion < 0x2070ab1)\nOLD33 = (sys.hexversion < 0x3030000)\nPY34 = (0x3040000 <= sys.hexversion < 0x3050000)\nif PY3: #XXX: get types from .objtypes ?\n    import builtins as __builtin__\n    from pickle import _Pickler as StockPickler, Unpickler as StockUnpickler\n    from _thread import LockType\n    if (sys.hexversion >= 0x30200f0):\n        from _thread import RLock as RLockType\n    else:\n        from threading import _RLock as RLockType\n   #from io import IOBase\n    from types import CodeType, FunctionType, MethodType, GeneratorType, \\\n        TracebackType, FrameType, ModuleType, BuiltinMethodType\n    BufferType = memoryview #XXX: unregistered\n    ClassType = type # no 'old-style' classes\n    EllipsisType = type(Ellipsis)\n   #FileType = IOBase\n    NotImplementedType = type(NotImplemented)\n    SliceType = slice\n    TypeType = type # 'new-style' classes #XXX: unregistered\n    XRangeType = range\n    if OLD33:\n        DictProxyType = type(object.__dict__)\n    else:\n        from types import MappingProxyType as DictProxyType\nelse:\n    import __builtin__\n    from pickle import Pickler as StockPickler, Unpickler as StockUnpickler\n    from thread import LockType\n    from threading import _RLock as RLockType\n    from types import CodeType, FunctionType, ClassType, MethodType, \\\n         GeneratorType, DictProxyType, XRangeType, SliceType, TracebackType, \\\n         NotImplementedType, EllipsisType, FrameType, ModuleType, \\\n         BufferType, BuiltinMethodType, TypeType\nfrom pickle import HIGHEST_PROTOCOL, PicklingError, UnpicklingError\ntry:\n    from pickle import DEFAULT_PROTOCOL\nexcept ImportError:\n    DEFAULT_PROTOCOL = HIGHEST_PROTOCOL\nimport __main__ as _main_module\nimport marshal\nimport gc\n# import zlib\nfrom weakref import ReferenceType, ProxyType, CallableProxyType\nfrom functools import partial\nfrom operator import itemgetter, attrgetter\n# new in python3.3\nif sys.hexversion < 0x03030000:\n    FileNotFoundError = IOError\nif PY3 and sys.hexversion < 0x03040000:\n    GENERATOR_FAIL = True\nelse: GENERATOR_FAIL = False    \nif PY3:\n    import importlib.machinery\n    EXTENSION_SUFFIXES = tuple(importlib.machinery.EXTENSION_SUFFIXES)\nelse:\n    import imp\n    EXTENSION_SUFFIXES = tuple(suffix\n                               for (suffix, _, s_type) in imp.get_suffixes()\n                               if s_type == imp.C_EXTENSION)\ntry:\n    import ctypes\n    HAS_CTYPES = True\n    # if using `pypy`, pythonapi is not found\n    IS_PYPY = not hasattr(ctypes, 'pythonapi')\nexcept ImportError:\n    HAS_CTYPES = False\n    IS_PYPY = False\nNumpyUfuncType = None\nNumpyArrayType = None\ntry:\n    if OLDER:\n        raise AttributeError('find_spec not found')\n    import importlib\n    if not importlib.machinery.PathFinder().find_spec('numpy'):\n        raise ImportError(\"No module named 'numpy'\")\n    NumpyUfuncType = True\n    NumpyArrayType = True\nexcept AttributeError:\n    try:\n        import imp\n        imp.find_module('numpy')\n        NumpyUfuncType = True\n        NumpyArrayType = True\n    except ImportError:\n        pass\nexcept ImportError:\n    pass\ndef __hook__():\n    global NumpyArrayType, NumpyUfuncType\n    from numpy import ufunc as NumpyUfuncType\n    from numpy import ndarray as NumpyArrayType\n    return True\nif NumpyArrayType: # then has numpy\n    def ndarraysubclassinstance(obj):\n        if type(obj) in (TypeType, ClassType):\n            return False # all classes return False\n        try: # check if is ndarray, and elif is subclass of ndarray\n            cls = getattr(obj, '__class__', None)\n            if cls is None: return False\n            elif cls is TypeType: return False\n            elif 'numpy.ndarray' not in str(getattr(cls, 'mro', int.mro)()):\n                return False\n        except ReferenceError: return False # handle 'R3' weakref in 3.x\n        except TypeError: return False\n        # anything below here is a numpy array (or subclass) instance\n        __hook__() # import numpy (so the following works!!!)\n        # verify that __reduce__ has not been overridden\n        NumpyInstance = NumpyArrayType((0,),'int8')\n        if id(obj.__reduce_ex__) == id(NumpyInstance.__reduce_ex__) and \\\n           id(obj.__reduce__) == id(NumpyInstance.__reduce__): return True\n        return False\n    def numpyufunc(obj):\n        if type(obj) in (TypeType, ClassType):\n            return False # all classes return False\n        try: # check if is ufunc\n            cls = getattr(obj, '__class__', None)\n            if cls is None: return False\n            elif cls is TypeType: return False\n            if 'numpy.ufunc' not in str(getattr(cls, 'mro', int.mro)()):\n                return False\n        except ReferenceError: return False # handle 'R3' weakref in 3.x\n        except TypeError: return False\n        # anything below here is a numpy ufunc\n        return True\nelse:\n    def ndarraysubclassinstance(obj): return False\n    def numpyufunc(obj): return False\n\n# make sure to add these 'hand-built' types to _typemap\nif PY3:\n    CellType = type((lambda x: lambda y: x)(0).__closure__[0])\nelse:\n    CellType = type((lambda x: lambda y: x)(0).func_closure[0])\n# new in python2.5\nif sys.hexversion >= 0x20500f0:\n    from types import GetSetDescriptorType\n    if not IS_PYPY:\n        from types import MemberDescriptorType\n    else:\n        # oddly, MemberDescriptorType is GetSetDescriptorType\n        # while, member_descriptor does exist otherwise... is this a pypy bug?\n        class _member(object):\n            __slots__ = ['descriptor']\n        MemberDescriptorType = type(_member.descriptor)\nif IS_PYPY:\n    WrapperDescriptorType = MethodType\n    MethodDescriptorType = FunctionType\n    ClassMethodDescriptorType = FunctionType\nelse:\n    WrapperDescriptorType = type(type.__repr__)\n    MethodDescriptorType = type(type.__dict__['mro'])\n    ClassMethodDescriptorType = type(type.__dict__['__prepare__' if PY3 else 'mro'])\n\nMethodWrapperType = type([].__repr__)\nPartialType = type(partial(int,base=2))\nSuperType = type(super(Exception, TypeError()))\nItemGetterType = type(itemgetter(0))\nAttrGetterType = type(attrgetter('__repr__'))\n\ndef get_file_type(*args, **kwargs):\n    open = kwargs.pop(\"open\", __builtin__.open)\n    f = open(os.devnull, *args, **kwargs)\n    t = type(f)\n    f.close()\n    return t\n\nFileType = get_file_type('rb', buffering=0)\nTextWrapperType = get_file_type('r', buffering=-1)\nBufferedRandomType = get_file_type('r+b', buffering=-1)\nBufferedReaderType = get_file_type('rb', buffering=-1)\nBufferedWriterType = get_file_type('wb', buffering=-1)\ntry:\n    from _pyio import open as _open\n    PyTextWrapperType = get_file_type('r', buffering=-1, open=_open)\n    PyBufferedRandomType = get_file_type('r+b', buffering=-1, open=_open)\n    PyBufferedReaderType = get_file_type('rb', buffering=-1, open=_open)\n    PyBufferedWriterType = get_file_type('wb', buffering=-1, open=_open)\nexcept ImportError:\n    PyTextWrapperType = PyBufferedRandomType = PyBufferedReaderType = PyBufferedWriterType = None\ntry:\n    from cStringIO import StringIO, InputType, OutputType\nexcept ImportError:\n    if PY3:\n        from io import BytesIO as StringIO\n    else:\n        from StringIO import StringIO\n    InputType = OutputType = None\nif not IS_PYPY:\n    from socket import socket as SocketType\n    try: #FIXME: additionally calls ForkingPickler.register several times\n        from multiprocessing.reduction import _reduce_socket as reduce_socket\n    except ImportError:\n        from multiprocessing.reduction import reduce_socket\ntry:\n    __IPYTHON__ is True # is ipython\n    ExitType = None     # IPython.core.autocall.ExitAutocall\n    singletontypes = ['exit', 'quit', 'get_ipython']\nexcept NameError:\n    try: ExitType = type(exit) # apparently 'exit' can be removed\n    except NameError: ExitType = None\n    singletontypes = []\n\n### File modes\n# Pickles the file handle, preserving mode. The position of the unpickled\n# object is as for a new file handle.\nHANDLE_FMODE = 0\n# Pickles the file contents, creating a new file if on load the file does\n# not exist. The position = min(pickled position, EOF) and mode is chosen\n# as such that \"best\" preserves behavior of the original file.\nCONTENTS_FMODE = 1\n# Pickles the entire file (handle and contents), preserving mode and position.\nFILE_FMODE = 2\n\n### Shorthands (modified from python2.5/lib/pickle.py)\ndef copy(obj, *args, **kwds):\n    \"\"\"use pickling to 'copy' an object\"\"\"\n    ignore = kwds.pop('ignore', Unpickler.settings['ignore'])\n    return loads(dumps(obj, *args, **kwds), ignore=ignore)\n\ndef dump(obj, file, protocol=None, byref=None, fmode=None, recurse=None, **kwds):#, strictio=None):\n    \"\"\"pickle an object to a file\"\"\"\n    from .settings import settings\n    protocol = settings['protocol'] if protocol is None else int(protocol)\n    _kwds = kwds.copy()\n    _kwds.update(dict(byref=byref, fmode=fmode, recurse=recurse))\n    Pickler(file, protocol, **_kwds).dump(obj)\n    return\n\ndef dumps(obj, protocol=None, byref=None, fmode=None, recurse=None, **kwds):#, strictio=None):\n    \"\"\"pickle an object to a string\"\"\"\n    file = StringIO()\n    dump(obj, file, protocol, byref, fmode, recurse, **kwds)#, strictio)\n    return file.getvalue()\n\ndef load(file, ignore=None, **kwds):\n    \"\"\"unpickle an object from a file\"\"\"\n    return Unpickler(file, ignore=ignore, **kwds).load()\n\ndef loads(str, ignore=None, **kwds):\n    \"\"\"unpickle an object from a string\"\"\"\n    file = StringIO(str)\n    return load(file, ignore, **kwds)\n\n# def dumpzs(obj, protocol=None):\n#     \"\"\"pickle an object to a compressed string\"\"\"\n#     return zlib.compress(dumps(obj, protocol))\n\n# def loadzs(str):\n#     \"\"\"unpickle an object from a compressed string\"\"\"\n#     return loads(zlib.decompress(str))\n\n### End: Shorthands ###\n\n### Pickle the Interpreter Session\ndef _module_map():\n    \"\"\"get map of imported modules\"\"\"\n    from collections import defaultdict\n    modmap = defaultdict(list)\n    items = 'items' if PY3 else 'iteritems'\n    for name, module in getattr(sys.modules, items)():\n        if module is None:\n            continue\n        for objname, obj in module.__dict__.items():\n            modmap[objname].append((obj, name))\n    return modmap\n\ndef _lookup_module(modmap, name, obj, main_module): #FIXME: needs work\n    \"\"\"lookup name if module is imported\"\"\"\n    for modobj, modname in modmap[name]:\n        if modobj is obj and modname != main_module.__name__:\n            return modname\n\ndef _stash_modules(main_module):\n    modmap = _module_map()\n    imported = []\n    original = {}\n    items = 'items' if PY3 else 'iteritems'\n    for name, obj in getattr(main_module.__dict__, items)():\n        source_module = _lookup_module(modmap, name, obj, main_module)\n        if source_module:\n            imported.append((source_module, name))\n        else:\n            original[name] = obj\n    if len(imported):\n        import types\n        newmod = types.ModuleType(main_module.__name__)\n        newmod.__dict__.update(original)\n        newmod.__dill_imported = imported\n        return newmod\n    else:\n        return original\n\ndef _restore_modules(main_module):\n    if '__dill_imported' not in main_module.__dict__:\n        return\n    imports = main_module.__dict__.pop('__dill_imported')\n    for module, name in imports:\n        exec(\"from %s import %s\" % (module, name), main_module.__dict__)\n\n#NOTE: 06/03/15 renamed main_module to main\ndef dump_session(filename='/tmp/session.pkl', main=None, byref=False, **kwds):\n    \"\"\"pickle the current state of __main__ to a file\"\"\"\n    from .settings import settings\n    protocol = settings['protocol']\n    if main is None: main = _main_module\n    if hasattr(filename, 'write'):\n        f = filename\n    else:\n        f = open(filename, 'wb')\n    try:\n        if byref:\n            main = _stash_modules(main)\n        pickler = Pickler(f, protocol, **kwds)\n        pickler._main = main     #FIXME: dill.settings are disabled\n        pickler._byref = False   # disable pickling by name reference\n        pickler._recurse = False # disable pickling recursion for globals\n        pickler._session = True  # is best indicator of when pickling a session\n        pickler.dump(main)\n    finally:\n        if f is not filename:  # If newly opened file\n            f.close()\n    return\n\ndef load_session(filename='/tmp/session.pkl', main=None, **kwds):\n    \"\"\"update the __main__ module with the state from the session file\"\"\"\n    if main is None: main = _main_module\n    if hasattr(filename, 'read'):\n        f = filename\n    else:\n        f = open(filename, 'rb')\n    try: #FIXME: dill.settings are disabled\n        unpickler = Unpickler(f, **kwds)\n        unpickler._main = main\n        unpickler._session = True\n        module = unpickler.load()\n        unpickler._session = False\n        main.__dict__.update(module.__dict__)\n        _restore_modules(main)\n    finally:\n        if f is not filename:  # If newly opened file\n            f.close()\n    return\n\n### End: Pickle the Interpreter\n\nclass MetaCatchingDict(dict):\n    def get(self, key, default=None):\n        try:\n            return self[key]\n        except KeyError:\n            return default\n\n    def __missing__(self, key):\n        if issubclass(key, type):\n            return save_type\n        else:\n            raise KeyError()\n\n\n### Extend the Picklers\nclass Pickler(StockPickler):\n    \"\"\"python's Pickler extended to interpreter sessions\"\"\"\n    dispatch = MetaCatchingDict(StockPickler.dispatch.copy())\n    _session = False\n    from .settings import settings\n\n    def __init__(self, *args, **kwds):\n        settings = Pickler.settings\n        _byref = kwds.pop('byref', None)\n       #_strictio = kwds.pop('strictio', None)\n        _fmode = kwds.pop('fmode', None)\n        _recurse = kwds.pop('recurse', None)\n        StockPickler.__init__(self, *args, **kwds)\n        self._main = _main_module\n        self._diff_cache = {}\n        self._byref = settings['byref'] if _byref is None else _byref\n        self._strictio = False #_strictio\n        self._fmode = settings['fmode'] if _fmode is None else _fmode\n        self._recurse = settings['recurse'] if _recurse is None else _recurse\n\n    def dump(self, obj): #NOTE: if settings change, need to update attributes\n        stack.clear()  # clear record of 'recursion-sensitive' pickled objects\n        # register if the object is a numpy ufunc\n        # thanks to Paul Kienzle for pointing out ufuncs didn't pickle\n        if NumpyUfuncType and numpyufunc(obj):\n            @register(type(obj))\n            def save_numpy_ufunc(pickler, obj):\n                log.info(\"Nu: %s\" % obj)\n                name = getattr(obj, '__qualname__', getattr(obj, '__name__', None))\n                StockPickler.save_global(pickler, obj, name=name)\n                log.info(\"# Nu\")\n                return\n            # NOTE: the above 'save' performs like:\n            #   import copy_reg\n            #   def udump(f): return f.__name__\n            #   def uload(name): return getattr(numpy, name)\n            #   copy_reg.pickle(NumpyUfuncType, udump, uload)\n        # register if the object is a subclassed numpy array instance\n        if NumpyArrayType and ndarraysubclassinstance(obj):\n            @register(type(obj))\n            def save_numpy_array(pickler, obj):\n                log.info(\"Nu: (%s, %s)\" % (obj.shape,obj.dtype))\n                npdict = getattr(obj, '__dict__', None)\n                f, args, state = obj.__reduce__()\n                pickler.save_reduce(_create_array, (f,args,state,npdict), obj=obj)\n                log.info(\"# Nu\")\n                return\n        # end hack\n        if GENERATOR_FAIL and type(obj) == GeneratorType:\n            msg = \"Can't pickle %s: attribute lookup builtins.generator failed\" % GeneratorType\n            raise PicklingError(msg)\n        else:\n            StockPickler.dump(self, obj)\n        stack.clear()  # clear record of 'recursion-sensitive' pickled objects\n        return\n    dump.__doc__ = StockPickler.dump.__doc__\n    pass\n\nclass Unpickler(StockUnpickler):\n    \"\"\"python's Unpickler extended to interpreter sessions and more types\"\"\"\n    from .settings import settings\n    _session = False\n\n    def find_class(self, module, name):\n        if (module, name) == ('__builtin__', '__main__'):\n            return self._main.__dict__ #XXX: above set w/save_module_dict\n        elif (module, name) == ('__builtin__', 'NoneType'):\n            return type(None) #XXX: special case: NoneType missing\n        if module == 'dill.dill': module = 'dill._dill'\n        return StockUnpickler.find_class(self, module, name)\n\n    def __init__(self, *args, **kwds):\n        settings = Pickler.settings\n        _ignore = kwds.pop('ignore', None)\n        StockUnpickler.__init__(self, *args, **kwds)\n        self._main = _main_module\n        self._ignore = settings['ignore'] if _ignore is None else _ignore\n\n    def load(self): #NOTE: if settings change, need to update attributes\n        obj = StockUnpickler.load(self)\n        if type(obj).__module__ == getattr(_main_module, '__name__', '__main__'):\n            if not self._ignore:\n                # point obj class to main\n                try: obj.__class__ = getattr(self._main, type(obj).__name__)\n                except (AttributeError,TypeError): pass # defined in a file\n       #_main_module.__dict__.update(obj.__dict__) #XXX: should update globals ?\n        return obj\n    load.__doc__ = StockUnpickler.load.__doc__\n    pass\n\n'''\ndef dispatch_table():\n    \"\"\"get the dispatch table of registered types\"\"\"\n    return Pickler.dispatch\n'''\n\npickle_dispatch_copy = StockPickler.dispatch.copy()\n\ndef pickle(t, func):\n    \"\"\"expose dispatch table for user-created extensions\"\"\"\n    Pickler.dispatch[t] = func\n    return\n\ndef register(t):\n    \"\"\"register type to Pickler's dispatch table \"\"\"\n    def proxy(func):\n        Pickler.dispatch[t] = func\n        return func\n    return proxy\n\ndef _revert_extension():\n    \"\"\"drop dill-registered types from pickle's dispatch table\"\"\"\n    for type, func in list(StockPickler.dispatch.items()):\n        if func.__module__ == __name__:\n            del StockPickler.dispatch[type]\n            if type in pickle_dispatch_copy:\n                StockPickler.dispatch[type] = pickle_dispatch_copy[type]\n\ndef use_diff(on=True):\n    \"\"\"\n    reduces size of pickles by only including object which have changed.\n    Decreases pickle size but increases CPU time needed.\n    Also helps avoid some unpicklable objects.\n    MUST be called at start of script, otherwise changes will not be recorded.\n    \"\"\"\n    global _use_diff, diff\n    _use_diff = on\n    if _use_diff and diff is None:\n        try:\n            from . import diff as d\n        except:\n            import diff as d\n        diff = d\n\ndef _create_typemap():\n    import types\n    if PY3:\n        d = dict(list(__builtin__.__dict__.items()) + \\\n                 list(types.__dict__.items())).items()\n        builtin = 'builtins'\n    else:\n        d = types.__dict__.iteritems()\n        builtin = '__builtin__'\n    for key, value in d:\n        if getattr(value, '__module__', None) == builtin \\\n        and type(value) is type:\n            yield key, value\n    return\n_reverse_typemap = dict(_create_typemap())\n_reverse_typemap.update({\n    'CellType': CellType,\n    'MethodWrapperType': MethodWrapperType,\n    'PartialType': PartialType,\n    'SuperType': SuperType,\n    'ItemGetterType': ItemGetterType,\n    'AttrGetterType': AttrGetterType,\n    'FileType': FileType,\n    'BufferedRandomType': BufferedRandomType,\n    'BufferedReaderType': BufferedReaderType,\n    'BufferedWriterType': BufferedWriterType,\n    'TextWrapperType': TextWrapperType,\n    'PyBufferedRandomType': PyBufferedRandomType,\n    'PyBufferedReaderType': PyBufferedReaderType,\n    'PyBufferedWriterType': PyBufferedWriterType,\n    'PyTextWrapperType': PyTextWrapperType,\n})\nif ExitType:\n    _reverse_typemap['ExitType'] = ExitType\nif InputType:\n    _reverse_typemap['InputType'] = InputType\n    _reverse_typemap['OutputType'] = OutputType\nif not IS_PYPY:\n    _reverse_typemap['WrapperDescriptorType'] = WrapperDescriptorType\n    _reverse_typemap['MethodDescriptorType'] = MethodDescriptorType\n    _reverse_typemap['ClassMethodDescriptorType'] = ClassMethodDescriptorType\nelse:\n    _reverse_typemap['MemberDescriptorType'] = MemberDescriptorType\nif PY3:\n    _typemap = dict((v, k) for k, v in _reverse_typemap.items())\nelse:\n    _typemap = dict((v, k) for k, v in _reverse_typemap.iteritems())\n\ndef _unmarshal(string):\n    return marshal.loads(string)\n\ndef _load_type(name):\n    return _reverse_typemap[name]\n\ndef _create_type(typeobj, *args):\n    return typeobj(*args)\n\ndef _create_function(fcode, fglobals, fname=None, fdefaults=None,\n                     fclosure=None, fdict=None, fkwdefaults=None):\n    # same as FunctionType, but enable passing __dict__ to new function,\n    # __dict__ is the storehouse for attributes added after function creation\n    if fdict is None: fdict = dict()\n    func = FunctionType(fcode, fglobals or dict(), fname, fdefaults, fclosure)\n    func.__dict__.update(fdict) #XXX: better copy? option to copy?\n    if fkwdefaults is not None:\n        func.__kwdefaults__ = fkwdefaults\n    return func\n\ndef _create_code(*args):\n    if PY3 and hasattr(args[-3], 'encode'): #FIXME: from PY2 fails (optcode)\n        args = list(args)\n        args[-3] = args[-3].encode() # co_lnotab\n        args[-10] = args[-10].encode() # co_code\n    if hasattr(CodeType, 'co_posonlyargcount'):\n        if len(args) == 16: return CodeType(*args)\n        elif len(args) == 15: return CodeType(args[0], 0, *args[1:])\n        return CodeType(args[0], 0, 0, *args[1:])\n    elif hasattr(CodeType, 'co_kwonlyargcount'):\n        if len(args) == 16: return CodeType(args[0], *args[2:])\n        elif len(args) == 15: return CodeType(*args)\n        return CodeType(args[0], 0, *args[1:])\n    if len(args) == 16: return CodeType(args[0], *args[3:])\n    elif len(args) == 15: return CodeType(args[0], *args[2:])\n    return CodeType(*args)\n\ndef _create_ftype(ftypeobj, func, args, kwds):\n    if kwds is None:\n        kwds = {}\n    if args is None:\n        args = ()\n    return ftypeobj(func, *args, **kwds)\n\ndef _create_lock(locked, *args): #XXX: ignores 'blocking'\n    from threading import Lock\n    lock = Lock()\n    if locked:\n        if not lock.acquire(False):\n            raise UnpicklingError(\"Cannot acquire lock\")\n    return lock\n\ndef _create_rlock(count, owner, *args): #XXX: ignores 'blocking'\n    lock = RLockType()\n    if owner is not None:\n        lock._acquire_restore((count, owner))\n    if owner and not lock._is_owned():\n        raise UnpicklingError(\"Cannot acquire lock\")\n    return lock\n\n# thanks to matsjoyce for adding all the different file modes\ndef _create_filehandle(name, mode, position, closed, open, strictio, fmode, fdata): # buffering=0\n    # only pickles the handle, not the file contents... good? or StringIO(data)?\n    # (for file contents see: http://effbot.org/librarybook/copy-reg.htm)\n    # NOTE: handle special cases first (are there more special cases?)\n    names = {'<stdin>':sys.__stdin__, '<stdout>':sys.__stdout__,\n             '<stderr>':sys.__stderr__} #XXX: better fileno=(0,1,2) ?\n    if name in list(names.keys()):\n        f = names[name] #XXX: safer \"f=sys.stdin\"\n    elif name == '<tmpfile>':\n        f = os.tmpfile()\n    elif name == '<fdopen>':\n        import tempfile\n        f = tempfile.TemporaryFile(mode)\n    else:\n        # treat x mode as w mode\n        if \"x\" in mode and sys.hexversion < 0x03030000:\n            raise ValueError(\"invalid mode: '%s'\" % mode)\n        try:\n            exists = os.path.exists(name)\n        except:\n            exists = False\n        if not exists:\n            if strictio:\n                raise FileNotFoundError(\"[Errno 2] No such file or directory: '%s'\" % name)\n            elif \"r\" in mode and fmode != FILE_FMODE:\n                name = '<fdopen>' # or os.devnull?\n            current_size = 0 # or maintain position?\n        else:\n            current_size = os.path.getsize(name)\n\n        if position > current_size:\n            if strictio:\n                raise ValueError(\"invalid buffer size\")\n            elif fmode == CONTENTS_FMODE:\n                position = current_size\n        # try to open the file by name\n        # NOTE: has different fileno\n        try:\n            #FIXME: missing: *buffering*, encoding, softspace\n            if fmode == FILE_FMODE:\n                f = open(name, mode if \"w\" in mode else \"w\")\n                f.write(fdata)\n                if \"w\" not in mode:\n                    f.close()\n                    f = open(name, mode)\n            elif name == '<fdopen>': # file did not exist\n                import tempfile\n                f = tempfile.TemporaryFile(mode)\n            elif fmode == CONTENTS_FMODE \\\n               and (\"w\" in mode or \"x\" in mode):\n                # stop truncation when opening\n                flags = os.O_CREAT\n                if \"+\" in mode:\n                    flags |= os.O_RDWR\n                else:\n                    flags |= os.O_WRONLY\n                f = os.fdopen(os.open(name, flags), mode)\n                # set name to the correct value\n                if PY3:\n                    r = getattr(f, \"buffer\", f)\n                    r = getattr(r, \"raw\", r)\n                    r.name = name\n                else:\n                    if not HAS_CTYPES:\n                        raise ImportError(\"No module named 'ctypes'\")\n                    class FILE(ctypes.Structure):\n                        _fields_ = [(\"refcount\", ctypes.c_long),\n                                    (\"type_obj\", ctypes.py_object),\n                                    (\"file_pointer\", ctypes.c_voidp),\n                                    (\"name\", ctypes.py_object)]\n\n                    class PyObject(ctypes.Structure):\n                        _fields_ = [\n                            (\"ob_refcnt\", ctypes.c_int),\n                            (\"ob_type\", ctypes.py_object)\n                            ]\n                    #FIXME: CONTENTS_FMODE fails for pypy due to issue #1233\n                    #       https://bitbucket.org/pypy/pypy/issues/1233\n                    ctypes.cast(id(f), ctypes.POINTER(FILE)).contents.name = name\n                    ctypes.cast(id(name), ctypes.POINTER(PyObject)).contents.ob_refcnt += 1\n                assert f.name == name\n            else:\n                f = open(name, mode)\n        except (IOError, FileNotFoundError):\n            err = sys.exc_info()[1]\n            raise UnpicklingError(err)\n    if closed:\n        f.close()\n    elif position >= 0 and fmode != HANDLE_FMODE:\n        f.seek(position)\n    return f\n\ndef _create_stringi(value, position, closed):\n    f = StringIO(value)\n    if closed: f.close()\n    else: f.seek(position)\n    return f\n\ndef _create_stringo(value, position, closed):\n    f = StringIO()\n    if closed: f.close()\n    else:\n       f.write(value)\n       f.seek(position)\n    return f\n\nclass _itemgetter_helper(object):\n    def __init__(self):\n        self.items = []\n    def __getitem__(self, item):\n        self.items.append(item)\n        return\n\nclass _attrgetter_helper(object):\n    def __init__(self, attrs, index=None):\n        self.attrs = attrs\n        self.index = index\n    def __getattribute__(self, attr):\n        attrs = object.__getattribute__(self, \"attrs\")\n        index = object.__getattribute__(self, \"index\")\n        if index is None:\n            index = len(attrs)\n            attrs.append(attr)\n        else:\n            attrs[index] = \".\".join([attrs[index], attr])\n        return type(self)(attrs, index)\n\nif PY3:\n    def _create_cell(contents):\n        return (lambda y: contents).__closure__[0]\nelse:\n    def _create_cell(contents):\n        return (lambda y: contents).func_closure[0]\n\ndef _create_weakref(obj, *args):\n    from weakref import ref\n    if obj is None: # it's dead\n        if PY3:\n            from collections import UserDict\n        else:\n            from UserDict import UserDict\n        return ref(UserDict(), *args)\n    return ref(obj, *args)\n\ndef _create_weakproxy(obj, callable=False, *args):\n    from weakref import proxy\n    if obj is None: # it's dead\n        if callable: return proxy(lambda x:x, *args)\n        if PY3:\n            from collections import UserDict\n        else:\n            from UserDict import UserDict\n        return proxy(UserDict(), *args)\n    return proxy(obj, *args)\n\ndef _eval_repr(repr_str):\n    return eval(repr_str)\n\ndef _create_array(f, args, state, npdict=None):\n   #array = numpy.core.multiarray._reconstruct(*args)\n    array = f(*args)\n    array.__setstate__(state)\n    if npdict is not None: # we also have saved state in __dict__\n        array.__dict__.update(npdict)\n    return array\n\ndef _create_namedtuple(name, fieldnames, modulename):\n    class_ = _import_module(modulename + '.' + name, safe=True)\n    if class_ is not None:\n        return class_\n    import collections\n    t = collections.namedtuple(name, fieldnames)\n    t.__module__ = modulename\n    return t\n\ndef _getattr(objclass, name, repr_str):\n    # hack to grab the reference directly\n    try: #XXX: works only for __builtin__ ?\n        attr = repr_str.split(\"'\")[3]\n        return eval(attr+'.__dict__[\"'+name+'\"]')\n    except:\n        try:\n            attr = objclass.__dict__\n            if type(attr) is DictProxyType:\n                attr = attr[name]\n            else:\n                attr = getattr(objclass,name)\n        except:\n            attr = getattr(objclass,name)\n        return attr\n\ndef _get_attr(self, name):\n    # stop recursive pickling\n    return getattr(self, name, None) or getattr(__builtin__, name)\n\ndef _dict_from_dictproxy(dictproxy):\n    _dict = dictproxy.copy() # convert dictproxy to dict\n    _dict.pop('__dict__', None)\n    _dict.pop('__weakref__', None)\n    _dict.pop('__prepare__', None)\n    return _dict\n\ndef _import_module(import_name, safe=False):\n    try:\n        if '.' in import_name:\n            items = import_name.split('.')\n            module = '.'.join(items[:-1])\n            obj = items[-1]\n        else:\n            return __import__(import_name)\n        return getattr(__import__(module, None, None, [obj]), obj)\n    except (ImportError, AttributeError):\n        if safe:\n            return None\n        raise\n\ndef _locate_function(obj, session=False):\n    if obj.__module__ in ['__main__', None]: # and session:\n        return False\n    found = _import_module(obj.__module__ + '.' + obj.__name__, safe=True)\n    return found is obj\n\n#@register(CodeType)\n#def save_code(pickler, obj):\n#    log.info(\"Co: %s\" % obj)\n#    pickler.save_reduce(_unmarshal, (marshal.dumps(obj),), obj=obj)\n#    log.info(\"# Co\")\n#    return\n\n# The following function is based on 'save_codeobject' from 'cloudpickle'\n# Copyright (c) 2012, Regents of the University of California.\n# Copyright (c) 2009 `PiCloud, Inc. <http://www.picloud.com>`_.\n# License: https://github.com/cloudpipe/cloudpickle/blob/master/LICENSE\n@register(CodeType)\ndef save_code(pickler, obj):\n    log.info(\"Co: %s\" % obj)\n    if PY3:\n        if hasattr(obj, \"co_posonlyargcount\"):\n            args = (\n                obj.co_argcount, obj.co_posonlyargcount,\n                obj.co_kwonlyargcount, obj.co_nlocals, obj.co_stacksize,\n                obj.co_flags, obj.co_code, obj.co_consts, obj.co_names,\n                obj.co_varnames, obj.co_filename, obj.co_name,\n                obj.co_firstlineno, obj.co_lnotab, obj.co_freevars,\n                obj.co_cellvars\n        )\n        else:\n            args = (\n                obj.co_argcount, obj.co_kwonlyargcount, obj.co_nlocals,\n                obj.co_stacksize, obj.co_flags, obj.co_code, obj.co_consts,\n                obj.co_names, obj.co_varnames, obj.co_filename,\n                obj.co_name, obj.co_firstlineno, obj.co_lnotab,\n                obj.co_freevars, obj.co_cellvars\n        )\n    else:\n        args = (\n            obj.co_argcount, obj.co_nlocals, obj.co_stacksize, obj.co_flags,\n            obj.co_code, obj.co_consts, obj.co_names, obj.co_varnames,\n            obj.co_filename, obj.co_name, obj.co_firstlineno, obj.co_lnotab,\n            obj.co_freevars, obj.co_cellvars\n        )\n\n    pickler.save_reduce(_create_code, args, obj=obj)\n    log.info(\"# Co\")\n    return\n\n@register(dict)\ndef save_module_dict(pickler, obj):\n    if is_dill(pickler, child=False) and obj == pickler._main.__dict__ and not pickler._session:\n        log.info(\"D1: <dict%s\" % str(obj.__repr__).split('dict')[-1]) # obj\n        if PY3:\n            pickler.write(bytes('c__builtin__\\n__main__\\n', 'UTF-8'))\n        else:\n            pickler.write('c__builtin__\\n__main__\\n')\n        log.info(\"# D1\")\n    elif (not is_dill(pickler, child=False)) and (obj == _main_module.__dict__):\n        log.info(\"D3: <dict%s\" % str(obj.__repr__).split('dict')[-1]) # obj\n        if PY3:\n            pickler.write(bytes('c__main__\\n__dict__\\n', 'UTF-8'))\n        else:\n            pickler.write('c__main__\\n__dict__\\n')   #XXX: works in general?\n        log.info(\"# D3\")\n    elif '__name__' in obj and obj != _main_module.__dict__ \\\n    and type(obj['__name__']) is str \\\n    and obj is getattr(_import_module(obj['__name__'],True), '__dict__', None):\n        log.info(\"D4: <dict%s\" % str(obj.__repr__).split('dict')[-1]) # obj\n        if PY3:\n            pickler.write(bytes('c%s\\n__dict__\\n' % obj['__name__'], 'UTF-8'))\n        else:\n            pickler.write('c%s\\n__dict__\\n' % obj['__name__'])\n        log.info(\"# D4\")\n    else:\n        log.info(\"D2: <dict%s\" % str(obj.__repr__).split('dict')[-1]) # obj\n        if is_dill(pickler, child=False) and pickler._session:\n            # we only care about session the first pass thru\n            pickler._session = False\n        StockPickler.save_dict(pickler, obj)\n        log.info(\"# D2\")\n    return\n\n@register(ClassType)\ndef save_classobj(pickler, obj): #FIXME: enable pickler._byref\n   #stack[id(obj)] = len(stack), obj\n    if obj.__module__ == '__main__': #XXX: use _main_module.__name__ everywhere?\n        log.info(\"C1: %s\" % obj)\n        pickler.save_reduce(ClassType, (obj.__name__, obj.__bases__,\n                                        obj.__dict__), obj=obj)\n                                       #XXX: or obj.__dict__.copy()), obj=obj) ?\n        log.info(\"# C1\")\n    else:\n        log.info(\"C2: %s\" % obj)\n        name = getattr(obj, '__qualname__', getattr(obj, '__name__', None))\n        StockPickler.save_global(pickler, obj, name=name)\n        log.info(\"# C2\")\n    return\n\n@register(LockType)\ndef save_lock(pickler, obj):\n    log.info(\"Lo: %s\" % obj)\n    pickler.save_reduce(_create_lock, (obj.locked(),), obj=obj)\n    log.info(\"# Lo\")\n    return\n\n@register(RLockType)\ndef save_rlock(pickler, obj):\n    log.info(\"RL: %s\" % obj)\n    r = obj.__repr__() # don't use _release_save as it unlocks the lock\n    count = int(r.split('count=')[1].split()[0].rstrip('>'))\n    owner = int(r.split('owner=')[1].split()[0]) if PY3 else getattr(obj, '_RLock__owner')\n    pickler.save_reduce(_create_rlock, (count,owner,), obj=obj)\n    log.info(\"# RL\")\n    return\n\nif not IS_PYPY:\n    #@register(SocketType) #FIXME: causes multiprocess test_pickling FAIL\n    def save_socket(pickler, obj):\n        log.info(\"So: %s\" % obj)\n        pickler.save_reduce(*reduce_socket(obj))\n        log.info(\"# So\")\n        return\n\n@register(ItemGetterType)\ndef save_itemgetter(pickler, obj):\n    log.info(\"Ig: %s\" % obj)\n    helper = _itemgetter_helper()\n    obj(helper)\n    pickler.save_reduce(type(obj), tuple(helper.items), obj=obj)\n    log.info(\"# Ig\")\n    return\n\n@register(AttrGetterType)\ndef save_attrgetter(pickler, obj):\n    log.info(\"Ag: %s\" % obj)\n    attrs = []\n    helper = _attrgetter_helper(attrs)\n    obj(helper)\n    pickler.save_reduce(type(obj), tuple(attrs), obj=obj)\n    log.info(\"# Ag\")\n    return\n\ndef _save_file(pickler, obj, open_):\n    if obj.closed:\n        position = 0\n    else:\n        obj.flush()\n        if obj in (sys.__stdout__, sys.__stderr__, sys.__stdin__):\n            position = -1\n        else:\n            position = obj.tell()\n    if is_dill(pickler, child=True) and pickler._fmode == FILE_FMODE:\n        f = open_(obj.name, \"r\")\n        fdata = f.read()\n        f.close()\n    else:\n        fdata = \"\"\n    if is_dill(pickler, child=True):\n        strictio = pickler._strictio\n        fmode = pickler._fmode\n    else:\n        strictio = False\n        fmode = 0 # HANDLE_FMODE\n    pickler.save_reduce(_create_filehandle, (obj.name, obj.mode, position,\n                                             obj.closed, open_, strictio,\n                                             fmode, fdata), obj=obj)\n    return\n\n\n@register(FileType) #XXX: in 3.x has buffer=0, needs different _create?\n@register(BufferedRandomType)\n@register(BufferedReaderType)\n@register(BufferedWriterType)\n@register(TextWrapperType)\ndef save_file(pickler, obj):\n    log.info(\"Fi: %s\" % obj)\n    f = _save_file(pickler, obj, open)\n    log.info(\"# Fi\")\n    return f\n\nif PyTextWrapperType:\n    @register(PyBufferedRandomType)\n    @register(PyBufferedReaderType)\n    @register(PyBufferedWriterType)\n    @register(PyTextWrapperType)\n    def save_file(pickler, obj):\n        log.info(\"Fi: %s\" % obj)\n        f = _save_file(pickler, obj, _open)\n        log.info(\"# Fi\")\n        return f\n\n# The following two functions are based on 'saveCStringIoInput'\n# and 'saveCStringIoOutput' from spickle\n# Copyright (c) 2011 by science+computing ag\n# License: http://www.apache.org/licenses/LICENSE-2.0\nif InputType:\n    @register(InputType)\n    def save_stringi(pickler, obj):\n        log.info(\"Io: %s\" % obj)\n        if obj.closed:\n            value = ''; position = 0\n        else:\n            value = obj.getvalue(); position = obj.tell()\n        pickler.save_reduce(_create_stringi, (value, position, \\\n                                              obj.closed), obj=obj)\n        log.info(\"# Io\")\n        return\n\n    @register(OutputType)\n    def save_stringo(pickler, obj):\n        log.info(\"Io: %s\" % obj)\n        if obj.closed:\n            value = ''; position = 0\n        else:\n            value = obj.getvalue(); position = obj.tell()\n        pickler.save_reduce(_create_stringo, (value, position, \\\n                                              obj.closed), obj=obj)\n        log.info(\"# Io\")\n        return\n\n@register(PartialType)\ndef save_functor(pickler, obj):\n    log.info(\"Fu: %s\" % obj)\n    pickler.save_reduce(_create_ftype, (type(obj), obj.func, obj.args,\n                                        obj.keywords), obj=obj)\n    log.info(\"# Fu\")\n    return\n\n@register(SuperType)\ndef save_super(pickler, obj):\n    log.info(\"Su: %s\" % obj)\n    pickler.save_reduce(super, (obj.__thisclass__, obj.__self__), obj=obj)\n    log.info(\"# Su\")\n    return\n\n@register(BuiltinMethodType)\ndef save_builtin_method(pickler, obj):\n    if obj.__self__ is not None:\n        if obj.__self__ is __builtin__:\n            module = 'builtins' if PY3 else '__builtin__'\n            _t = \"B1\"\n            log.info(\"%s: %s\" % (_t, obj))\n        else:\n            module = obj.__self__\n            _t = \"B3\"\n            log.info(\"%s: %s\" % (_t, obj))\n        if is_dill(pickler, child=True):\n            _recurse = pickler._recurse\n            pickler._recurse = False\n        pickler.save_reduce(_get_attr, (module, obj.__name__), obj=obj)\n        if is_dill(pickler, child=True):\n            pickler._recurse = _recurse\n        log.info(\"# %s\" % _t)\n    else:\n        log.info(\"B2: %s\" % obj)\n        name = getattr(obj, '__qualname__', getattr(obj, '__name__', None))\n        StockPickler.save_global(pickler, obj, name=name)\n        log.info(\"# B2\")\n    return\n\n@register(MethodType) #FIXME: fails for 'hidden' or 'name-mangled' classes\ndef save_instancemethod0(pickler, obj):# example: cStringIO.StringI\n    log.info(\"Me: %s\" % obj) #XXX: obj.__dict__ handled elsewhere?\n    if PY3:\n        pickler.save_reduce(MethodType, (obj.__func__, obj.__self__), obj=obj)\n    else:\n        pickler.save_reduce(MethodType, (obj.im_func, obj.im_self,\n                                         obj.im_class), obj=obj)\n    log.info(\"# Me\")\n    return\n\nif sys.hexversion >= 0x20500f0:\n    if not IS_PYPY:\n        @register(MemberDescriptorType)\n        @register(GetSetDescriptorType)\n        @register(MethodDescriptorType)\n        @register(WrapperDescriptorType)\n        @register(ClassMethodDescriptorType)\n        def save_wrapper_descriptor(pickler, obj):\n            log.info(\"Wr: %s\" % obj)\n            pickler.save_reduce(_getattr, (obj.__objclass__, obj.__name__,\n                                           obj.__repr__()), obj=obj)\n            log.info(\"# Wr\")\n            return\n    else:\n        @register(MemberDescriptorType)\n        @register(GetSetDescriptorType)\n        def save_wrapper_descriptor(pickler, obj):\n            log.info(\"Wr: %s\" % obj)\n            pickler.save_reduce(_getattr, (obj.__objclass__, obj.__name__,\n                                           obj.__repr__()), obj=obj)\n            log.info(\"# Wr\")\n            return\n\n    @register(MethodWrapperType)\n    def save_instancemethod(pickler, obj):\n        log.info(\"Mw: %s\" % obj)\n        pickler.save_reduce(getattr, (obj.__self__, obj.__name__), obj=obj)\n        log.info(\"# Mw\")\n        return\n\nelif not IS_PYPY:\n    @register(MethodDescriptorType)\n    @register(WrapperDescriptorType)\n    def save_wrapper_descriptor(pickler, obj):\n        log.info(\"Wr: %s\" % obj)\n        pickler.save_reduce(_getattr, (obj.__objclass__, obj.__name__,\n                                       obj.__repr__()), obj=obj)\n        log.info(\"# Wr\")\n        return\n\n@register(CellType)\ndef save_cell(pickler, obj):\n    log.info(\"Ce: %s\" % obj)\n    f = obj.cell_contents\n    pickler.save_reduce(_create_cell, (f,), obj=obj)\n    log.info(\"# Ce\")\n    return\n\nif not IS_PYPY:\n    if not OLD33:\n        @register(DictProxyType)\n        def save_dictproxy(pickler, obj):\n            log.info(\"Mp: %s\" % obj)\n            pickler.save_reduce(DictProxyType, (obj.copy(),), obj=obj)\n            log.info(\"# Mp\")\n            return\n    else:\n        # The following function is based on 'saveDictProxy' from spickle\n        # Copyright (c) 2011 by science+computing ag\n        # License: http://www.apache.org/licenses/LICENSE-2.0\n        @register(DictProxyType)\n        def save_dictproxy(pickler, obj):\n            log.info(\"Dp: %s\" % obj)\n            attr = obj.get('__dict__')\n           #pickler.save_reduce(_create_dictproxy, (attr,'nested'), obj=obj)\n            if type(attr) == GetSetDescriptorType and attr.__name__ == \"__dict__\" \\\n            and getattr(attr.__objclass__, \"__dict__\", None) == obj:\n                pickler.save_reduce(getattr, (attr.__objclass__,\"__dict__\"),obj=obj)\n                log.info(\"# Dp\")\n                return\n            # all bad below... so throw ReferenceError or TypeError\n            raise ReferenceError(\"%s does not reference a class __dict__\" % obj)\n\n@register(SliceType)\ndef save_slice(pickler, obj):\n    log.info(\"Sl: %s\" % obj)\n    pickler.save_reduce(slice, (obj.start, obj.stop, obj.step), obj=obj)\n    log.info(\"# Sl\")\n    return\n\n@register(XRangeType)\n@register(EllipsisType)\n@register(NotImplementedType)\ndef save_singleton(pickler, obj):\n    log.info(\"Si: %s\" % obj)\n    pickler.save_reduce(_eval_repr, (obj.__repr__(),), obj=obj)\n    log.info(\"# Si\")\n    return\n\ndef _proxy_helper(obj): # a dead proxy returns a reference to None\n    \"\"\"get memory address of proxy's reference object\"\"\"\n    _repr = repr(obj)\n    try: _str = str(obj)\n    except ReferenceError: # it's a dead proxy\n        return id(None)\n    if _str == _repr: return id(obj) # it's a repr\n    try: # either way, it's a proxy from here\n        address = int(_str.rstrip('>').split(' at ')[-1], base=16)\n    except ValueError: # special case: proxy of a 'type'\n        if not IS_PYPY:\n            address = int(_repr.rstrip('>').split(' at ')[-1], base=16)\n        else:\n            objects = iter(gc.get_objects())\n            for _obj in objects:\n                if repr(_obj) == _str: return id(_obj)\n            # all bad below... nothing found so throw ReferenceError\n            msg = \"Cannot reference object for proxy at '%s'\" % id(obj)\n            raise ReferenceError(msg)\n    return address\n\ndef _locate_object(address, module=None):\n    \"\"\"get object located at the given memory address (inverse of id(obj))\"\"\"\n    special = [None, True, False] #XXX: more...?\n    for obj in special:\n        if address == id(obj): return obj\n    if module:\n        if PY3:\n            objects = iter(module.__dict__.values())\n        else:\n            objects = module.__dict__.itervalues()\n    else: objects = iter(gc.get_objects())\n    for obj in objects:\n        if address == id(obj): return obj\n    # all bad below... nothing found so throw ReferenceError or TypeError\n    try: address = hex(address)\n    except TypeError:\n        raise TypeError(\"'%s' is not a valid memory address\" % str(address))\n    raise ReferenceError(\"Cannot reference object at '%s'\" % address)\n\n@register(ReferenceType)\ndef save_weakref(pickler, obj):\n    refobj = obj()\n    log.info(\"R1: %s\" % obj)\n   #refobj = ctypes.pythonapi.PyWeakref_GetObject(obj) # dead returns \"None\"\n    pickler.save_reduce(_create_weakref, (refobj,), obj=obj)\n    log.info(\"# R1\")\n    return\n\n@register(ProxyType)\n@register(CallableProxyType)\ndef save_weakproxy(pickler, obj):\n    refobj = _locate_object(_proxy_helper(obj))\n    try:\n        _t = \"R2\"\n        log.info(\"%s: %s\" % (_t, obj))\n    except ReferenceError:\n        _t = \"R3\"\n        log.info(\"%s: %s\" % (_t, sys.exc_info()[1]))\n   #callable = bool(getattr(refobj, '__call__', None))\n    if type(obj) is CallableProxyType: callable = True\n    else: callable = False\n    pickler.save_reduce(_create_weakproxy, (refobj, callable), obj=obj)\n    log.info(\"# %s\" % _t)\n    return\n\n@register(ModuleType)\ndef save_module(pickler, obj):\n    if False: #_use_diff:\n        if obj.__name__ != \"dill\":\n            try:\n                changed = diff.whats_changed(obj, seen=pickler._diff_cache)[0]\n            except RuntimeError:  # not memorised module, probably part of dill\n                pass\n            else:\n                log.info(\"M1: %s with diff\" % obj)\n                log.info(\"Diff: %s\", changed.keys())\n                pickler.save_reduce(_import_module, (obj.__name__,), obj=obj,\n                                    state=changed)\n                log.info(\"# M1\")\n                return\n\n        log.info(\"M2: %s\" % obj)\n        pickler.save_reduce(_import_module, (obj.__name__,), obj=obj)\n        log.info(\"# M2\")\n    else:\n        # if a module file name starts with prefix, it should be a builtin\n        # module, so should be pickled as a reference\n        if hasattr(obj, \"__file__\"):\n            names = [\"base_prefix\", \"base_exec_prefix\", \"exec_prefix\",\n                     \"prefix\", \"real_prefix\"]\n            builtin_mod = any(obj.__file__.startswith(os.path.normpath(getattr(sys, name)))\n                              for name in names if hasattr(sys, name))\n            builtin_mod = (builtin_mod or obj.__file__.endswith(EXTENSION_SUFFIXES) or\n                           'site-packages' in obj.__file__)\n        else:\n            builtin_mod = True\n        if obj.__name__ not in (\"builtins\", \"dill\") \\\n           and not builtin_mod or is_dill(pickler, child=True) and obj is pickler._main:\n            log.info(\"M1: %s\" % obj)\n            _main_dict = obj.__dict__.copy() #XXX: better no copy? option to copy?\n            [_main_dict.pop(item, None) for item in singletontypes\n                + [\"__builtins__\", \"__loader__\"]]\n            pickler.save_reduce(_import_module, (obj.__name__,), obj=obj,\n                                state=_main_dict)\n            log.info(\"# M1\")\n        else:\n            log.info(\"M2: %s\" % obj)\n            pickler.save_reduce(_import_module, (obj.__name__,), obj=obj)\n            log.info(\"# M2\")\n        return\n    return\n\n@register(TypeType)\ndef save_type(pickler, obj):\n   #stack[id(obj)] = len(stack), obj #XXX: probably don't obj in all cases below\n    if obj in _typemap:\n        log.info(\"T1: %s\" % obj)\n        pickler.save_reduce(_load_type, (_typemap[obj],), obj=obj)\n        log.info(\"# T1\")\n    elif issubclass(obj, tuple) and all([hasattr(obj, attr) for attr in ('_fields','_asdict','_make','_replace')]):\n        # special case: namedtuples\n        log.info(\"T6: %s\" % obj)\n        pickler.save_reduce(_create_namedtuple, (getattr(obj, \"__qualname__\", obj.__name__), obj._fields, obj.__module__), obj=obj)\n        log.info(\"# T6\")\n        return\n    elif obj.__module__ == '__main__':\n        if issubclass(type(obj), type):\n        #   try: # used when pickling the class as code (or the interpreter)\n            if is_dill(pickler, child=True) and not pickler._byref:\n                # thanks to Tom Stepleton pointing out pickler._session unneeded\n                _t = 'T2'\n                log.info(\"%s: %s\" % (_t, obj))\n                _dict = _dict_from_dictproxy(obj.__dict__)\n        #   except: # punt to StockPickler (pickle by class reference)\n            else:\n                log.info(\"T5: %s\" % obj)\n                name = getattr(obj, '__qualname__', getattr(obj, '__name__', None))\n                StockPickler.save_global(pickler, obj, name=name)\n                log.info(\"# T5\")\n                return\n        else:\n            _t = 'T3'\n            log.info(\"%s: %s\" % (_t, obj))\n            _dict = obj.__dict__\n       #print (_dict)\n       #print (\"%s\\n%s\" % (type(obj), obj.__name__))\n       #print (\"%s\\n%s\" % (obj.__bases__, obj.__dict__))\n        for name in _dict.get(\"__slots__\", []):\n            del _dict[name]\n        pickler.save_reduce(_create_type, (type(obj), obj.__name__,\n                                           obj.__bases__, _dict), obj=obj)\n        log.info(\"# %s\" % _t)\n    # special cases: NoneType\n    elif obj is type(None):\n        log.info(\"T7: %s\" % obj)\n        if PY3:\n            pickler.write(bytes('c__builtin__\\nNoneType\\n', 'UTF-8'))\n        else:\n            pickler.write('c__builtin__\\nNoneType\\n')\n        log.info(\"# T7\")\n    else:\n        log.info(\"T4: %s\" % obj)\n       #print (obj.__dict__)\n       #print (\"%s\\n%s\" % (type(obj), obj.__name__))\n       #print (\"%s\\n%s\" % (obj.__bases__, obj.__dict__))\n        name = getattr(obj, '__qualname__', getattr(obj, '__name__', None))\n        StockPickler.save_global(pickler, obj, name=name)\n        log.info(\"# T4\")\n    return\n\n@register(property)\ndef save_property(pickler, obj):\n    log.info(\"Pr: %s\" % obj)\n    pickler.save_reduce(property, (obj.fget, obj.fset, obj.fdel, obj.__doc__),\n                        obj=obj)\n    log.info(\"# Pr\")\n\n@register(staticmethod)\n@register(classmethod)\ndef save_classmethod(pickler, obj):\n    log.info(\"Cm: %s\" % obj)\n    im_func = '__func__' if PY3 else 'im_func'\n    try:\n        orig_func = getattr(obj, im_func)\n    except AttributeError:  # Python 2.6\n        orig_func = obj.__get__(None, object)\n        if isinstance(obj, classmethod):\n            orig_func = getattr(orig_func, im_func) # Unbind\n    pickler.save_reduce(type(obj), (orig_func,), obj=obj)\n    log.info(\"# Cm\")\n\n@register(FunctionType)\ndef save_function(pickler, obj):\n    if not _locate_function(obj): #, pickler._session):\n        log.info(\"F1: %s\" % obj)\n        if getattr(pickler, '_recurse', False):\n            # recurse to get all globals referred to by obj\n            from .detect import globalvars\n            globs = globalvars(obj, recurse=True, builtin=True)\n            # remove objects that have already been serialized\n           #stacktypes = (ClassType, TypeType, FunctionType)\n           #for key,value in list(globs.items()):\n           #    if isinstance(value, stacktypes) and id(value) in stack:\n           #        del globs[key]\n            # ABORT: if self-references, use _recurse=False\n            if id(obj) in stack: # or obj in globs.values():\n                globs = obj.__globals__ if PY3 else obj.func_globals\n        else:\n            globs = obj.__globals__ if PY3 else obj.func_globals\n        _byref = getattr(pickler, '_byref', None)\n        _recurse = getattr(pickler, '_recurse', None)\n        _memo = (id(obj) in stack) and (_recurse is not None)\n       #print(\"stack: %s + '%s'\" % (set(hex(i) for i in stack),hex(id(obj))))\n        stack[id(obj)] = len(stack), obj\n        if PY3:\n            #NOTE: workaround for 'super' (see issue #75)\n            _super = ('super' in getattr(obj.__code__,'co_names',())) and (_byref is not None)\n            if _super: pickler._byref = True\n            if _memo: pickler._recurse = False\n            fkwdefaults = getattr(obj, '__kwdefaults__', None)\n            pickler.save_reduce(_create_function, (obj.__code__,\n                                globs, obj.__name__,\n                                obj.__defaults__, obj.__closure__,\n                                obj.__dict__, fkwdefaults), obj=obj)\n        else:\n            _super = ('super' in getattr(obj.func_code,'co_names',())) and (_byref is not None) and getattr(pickler, '_recurse', False)\n            if _super: pickler._byref = True\n            if _memo: pickler._recurse = False\n            pickler.save_reduce(_create_function, (obj.func_code,\n                                globs, obj.func_name,\n                                obj.func_defaults, obj.func_closure,\n                                obj.__dict__), obj=obj)\n        if _super: pickler._byref = _byref\n        if _memo: pickler._recurse = _recurse\n       #clear = (_byref, _super, _recurse, _memo)\n       #print(clear + (OLDER,))\n        #NOTE: workaround for #234; \"partial\" still is problematic for recurse\n        if OLDER and not _byref and (_super or (not _super and _memo) or (not _super and not _memo and _recurse)): pickler.clear_memo()\n       #if _memo:\n       #    stack.remove(id(obj))\n       #   #pickler.clear_memo()\n       #   #StockPickler.clear_memo(pickler)\n        log.info(\"# F1\")\n    else:\n        log.info(\"F2: %s\" % obj)\n        name = getattr(obj, '__qualname__', getattr(obj, '__name__', None))\n        StockPickler.save_global(pickler, obj, name=name)\n        log.info(\"# F2\")\n    return\n\n# quick sanity checking\ndef pickles(obj,exact=False,safe=False,**kwds):\n    \"\"\"quick check if object pickles with dill\"\"\"\n    if safe: exceptions = (Exception,) # RuntimeError, ValueError\n    else:\n        exceptions = (TypeError, AssertionError, PicklingError, UnpicklingError)\n    try:\n        pik = copy(obj, **kwds)\n        try:\n            result = bool(pik.all() == obj.all())\n        except AttributeError:\n            result = pik == obj\n        if result: return True\n        if not exact:\n            result = type(pik) == type(obj)\n            if result: return result\n            # class instances might have been dumped with byref=False\n            return repr(type(pik)) == repr(type(obj)) #XXX: InstanceType?\n        return False\n    except exceptions:\n        return False\n\ndef check(obj, *args, **kwds):\n    \"\"\"check pickling of an object across another process\"\"\"\n   # == undocumented ==\n   # python -- the string path or executable name of the selected python\n   # verbose -- if True, be verbose about printing warning messages\n   # all other args and kwds are passed to dill.dumps #FIXME: ignore on load\n    verbose = kwds.pop('verbose', False)\n    python = kwds.pop('python', None)\n    if python is None:\n        import sys\n        python = sys.executable\n    # type check\n    isinstance(python, str)\n    import subprocess\n    fail = True\n    try:\n        _obj = dumps(obj, *args, **kwds)\n        fail = False\n    finally:\n        if fail and verbose:\n            print(\"DUMP FAILED\")\n    msg = \"%s -c import dill; print(dill.loads(%s))\" % (python, repr(_obj))\n    msg = \"SUCCESS\" if not subprocess.call(msg.split(None,2)) else \"LOAD FAILED\"\n    if verbose:\n        print(msg)\n    return\n\n# use to protect against missing attributes\ndef is_dill(pickler, child=None):\n    \"check the dill-ness of your pickler\"\n    if (child is False) or PY34 or (not hasattr(pickler.__class__, 'mro')):\n        return 'dill' in pickler.__module__\n    return Pickler in pickler.__class__.mro()\n\ndef _extend():\n    \"\"\"extend pickle with all of dill's registered types\"\"\"\n    # need to have pickle not choke on _main_module?  use is_dill(pickler)\n    for t,func in Pickler.dispatch.items():\n        try:\n            StockPickler.dispatch[t] = func\n        except: #TypeError, PicklingError, UnpicklingError\n            log.info(\"skip: %s\" % t)\n        else: pass\n    return\n\ndel diff, _use_diff, use_diff\n\n# EOF\n"
            },
            "_objects": {
                "type": "module",
                "extension": "py",
                "code": "#!/usr/bin/env python\n#\n# Author: Mike McKerns (mmckerns @caltech and @uqfoundation)\n# Copyright (c) 2008-2016 California Institute of Technology.\n# Copyright (c) 2016-2020 The Uncertainty Quantification Foundation.\n# License: 3-clause BSD.  The full license text is available at:\n#  - https://github.com/uqfoundation/dill/blob/master/LICENSE\n\"\"\"\nall Python Standard Library objects (currently: CH 1-15 @ 2.7)\nand some other common objects (i.e. numpy.ndarray)\n\"\"\"\n\n__all__ = ['registered','failures','succeeds']\n\n# helper imports\nimport warnings; warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nimport sys\nPY3 = (hex(sys.hexversion) >= '0x30000f0')\nif PY3:\n    import queue as Queue\n    import dbm as anydbm\nelse:\n    import Queue\n    import anydbm\n    import sets # deprecated/removed\n    import mutex # removed\ntry:\n    from cStringIO import StringIO # has StringI and StringO types\nexcept ImportError: # only has StringIO type\n    if PY3:\n        from io import BytesIO as StringIO\n    else:\n        from StringIO import StringIO\nimport re\nimport array\nimport collections\nimport codecs\nimport struct\nimport datetime\nimport calendar\nimport weakref\nimport pprint\nimport decimal\nimport functools\nimport itertools\nimport operator\nimport tempfile\nimport shelve\nimport zlib\nimport gzip\nimport zipfile\nimport tarfile\nimport xdrlib\nimport csv\nimport hashlib\nimport hmac\nimport os\nimport logging\nimport optparse\n#import __hello__\nimport threading\nimport socket\nimport contextlib\ntry:\n    import bz2\n    import sqlite3\n    if PY3: import dbm.ndbm as dbm\n    else: import dbm\n    HAS_ALL = True\nexcept ImportError: # Ubuntu\n    HAS_ALL = False\ntry:\n    #import curses\n    #from curses import textpad, panel\n    HAS_CURSES = True\nexcept ImportError: # Windows\n    HAS_CURSES = False\ntry:\n    import ctypes\n    HAS_CTYPES = True\n    # if using `pypy`, pythonapi is not found\n    IS_PYPY = not hasattr(ctypes, 'pythonapi')\nexcept ImportError: # MacPorts\n    HAS_CTYPES = False\n    IS_PYPY = False\n\n# helper objects\nclass _class:\n    def _method(self):\n        pass\n#   @classmethod\n#   def _clsmethod(cls): #XXX: test me\n#       pass\n#   @staticmethod\n#   def _static(self): #XXX: test me\n#       pass\nclass _class2:\n    def __call__(self):\n        pass\n_instance2 = _class2()\nclass _newclass(object):\n    def _method(self):\n        pass\n#   @classmethod\n#   def _clsmethod(cls): #XXX: test me\n#       pass\n#   @staticmethod\n#   def _static(self): #XXX: test me\n#       pass\nclass _newclass2(object):\n    __slots__ = ['descriptor']\ndef _function(x): yield x\ndef _function2():\n    try: raise\n    except:\n        from sys import exc_info\n        e, er, tb = exc_info()\n        return er, tb\nif HAS_CTYPES:\n    class _Struct(ctypes.Structure):\n        pass\n    _Struct._fields_ = [(\"_field\", ctypes.c_int),(\"next\", ctypes.POINTER(_Struct))]\n_filedescrip, _tempfile = tempfile.mkstemp('r') # deleted in cleanup\n_tmpf = tempfile.TemporaryFile('w')\n\n# put the objects in order, if possible\ntry:\n    from collections import OrderedDict as odict\nexcept ImportError:\n    try:\n        from ordereddict import OrderedDict as odict\n    except ImportError:\n        odict = dict\n# objects used by dill for type declaration\nregistered = d = odict()\n# objects dill fails to pickle\nfailures = x = odict()\n# all other type objects\nsucceeds = a = odict()\n\n# types module (part of CH 8)\na['BooleanType'] = bool(1)\na['BuiltinFunctionType'] = len\na['BuiltinMethodType'] = a['BuiltinFunctionType']\na['BytesType'] = _bytes = codecs.latin_1_encode('\\x00')[0] # bytes(1)\na['ClassType'] = _class\na['ComplexType'] = complex(1)\na['DictType'] = _dict = {}\na['DictionaryType'] = a['DictType']\na['FloatType'] = float(1)\na['FunctionType'] = _function\na['InstanceType'] = _instance = _class()\na['IntType'] = _int = int(1)\na['ListType'] = _list = []\na['NoneType'] = None\na['ObjectType'] = object()\na['StringType'] = _str = str(1)\na['TupleType'] = _tuple = ()\na['TypeType'] = type\nif PY3:\n    a['LongType'] = _int\n    a['UnicodeType'] = _str\nelse:\n    a['LongType'] = long(1)\n    a['UnicodeType'] = unicode(1)\n# built-in constants (CH 4)\na['CopyrightType'] = copyright\n# built-in types (CH 5)\na['ClassObjectType'] = _newclass # <type 'type'>\na['ClassInstanceType'] = _newclass() # <type 'class'>\na['SetType'] = _set = set()\na['FrozenSetType'] = frozenset()\n# built-in exceptions (CH 6)\na['ExceptionType'] = _exception = _function2()[0]\n# string services (CH 7)\na['SREPatternType'] = _srepattern = re.compile('')\n# data types (CH 8)\na['ArrayType'] = array.array(\"f\")\na['DequeType'] = collections.deque([0])\na['DefaultDictType'] = collections.defaultdict(_function, _dict)\na['TZInfoType'] = datetime.tzinfo()\na['DateTimeType'] = datetime.datetime.today()\na['CalendarType'] = calendar.Calendar()\nif not PY3:\n    a['SetsType'] = sets.Set()\n    a['ImmutableSetType'] = sets.ImmutableSet()\n    a['MutexType'] = mutex.mutex()\n# numeric and mathematical types (CH 9)\na['DecimalType'] = decimal.Decimal(1)\na['CountType'] = itertools.count(0)\n# data compression and archiving (CH 12)\na['TarInfoType'] = tarfile.TarInfo()\n# generic operating system services (CH 15)\na['LoggerType'] = logging.getLogger()\na['FormatterType'] = logging.Formatter() # pickle ok\na['FilterType'] = logging.Filter() # pickle ok\na['LogRecordType'] = logging.makeLogRecord(_dict) # pickle ok\na['OptionParserType'] = _oparser = optparse.OptionParser() # pickle ok\na['OptionGroupType'] = optparse.OptionGroup(_oparser,\"foo\") # pickle ok\na['OptionType'] = optparse.Option('--foo') # pickle ok\nif HAS_CTYPES:\n    a['CCharType'] = _cchar = ctypes.c_char()\n    a['CWCharType'] = ctypes.c_wchar() # fail == 2.6\n    a['CByteType'] = ctypes.c_byte()\n    a['CUByteType'] = ctypes.c_ubyte()\n    a['CShortType'] = ctypes.c_short()\n    a['CUShortType'] = ctypes.c_ushort()\n    a['CIntType'] = ctypes.c_int()\n    a['CUIntType'] = ctypes.c_uint()\n    a['CLongType'] = ctypes.c_long()\n    a['CULongType'] = ctypes.c_ulong()\n    a['CLongLongType'] = ctypes.c_longlong()\n    a['CULongLongType'] = ctypes.c_ulonglong()\n    a['CFloatType'] = ctypes.c_float()\n    a['CDoubleType'] = ctypes.c_double()\n    a['CSizeTType'] = ctypes.c_size_t()\n    a['CLibraryLoaderType'] = ctypes.cdll\n    a['StructureType'] = _Struct\n    if not IS_PYPY:\n        a['BigEndianStructureType'] = ctypes.BigEndianStructure()\n#NOTE: also LittleEndianStructureType and UnionType... abstract classes\n#NOTE: remember for ctypesobj.contents creates a new python object\n#NOTE: ctypes.c_int._objects is memberdescriptor for object's __dict__\n#NOTE: base class of all ctypes data types is non-public _CData\n\ntry: # python 2.6\n    import fractions\n    import number\n    import io\n    from io import StringIO as TextIO\n    # built-in functions (CH 2)\n    a['ByteArrayType'] = bytearray([1])\n    # numeric and mathematical types (CH 9)\n    a['FractionType'] = fractions.Fraction()\n    a['NumberType'] = numbers.Number()\n    # generic operating system services (CH 15)\n    a['IOBaseType'] = io.IOBase()\n    a['RawIOBaseType'] = io.RawIOBase()\n    a['TextIOBaseType'] = io.TextIOBase()\n    a['BufferedIOBaseType'] = io.BufferedIOBase()\n    a['UnicodeIOType'] = TextIO() # the new StringIO\n    a['LoggingAdapterType'] = logging.LoggingAdapter(_logger,_dict) # pickle ok\n    if HAS_CTYPES:\n        a['CBoolType'] = ctypes.c_bool(1)\n        a['CLongDoubleType'] = ctypes.c_longdouble()\nexcept ImportError:\n    pass\ntry: # python 2.7\n    import argparse\n    # data types (CH 8)\n    a['OrderedDictType'] = collections.OrderedDict(_dict)\n    a['CounterType'] = collections.Counter(_dict)\n    if HAS_CTYPES:\n        a['CSSizeTType'] = ctypes.c_ssize_t()\n    # generic operating system services (CH 15)\n    a['NullHandlerType'] = logging.NullHandler() # pickle ok  # new 2.7\n    a['ArgParseFileType'] = argparse.FileType() # pickle ok\nexcept (AttributeError, ImportError):\n    pass\n\n# -- pickle fails on all below here -----------------------------------------\n# types module (part of CH 8)\na['CodeType'] = compile('','','exec')\na['DictProxyType'] = type.__dict__\na['DictProxyType2'] = _newclass.__dict__\na['EllipsisType'] = Ellipsis\na['ClosedFileType'] = open(os.devnull, 'wb', buffering=0).close()\na['GetSetDescriptorType'] = array.array.typecode\na['LambdaType'] = _lambda = lambda x: lambda y: x #XXX: works when not imported!\na['MemberDescriptorType'] = _newclass2.descriptor\nif not IS_PYPY:\n    a['MemberDescriptorType2'] = datetime.timedelta.days\na['MethodType'] = _method = _class()._method #XXX: works when not imported!\na['ModuleType'] = datetime\na['NotImplementedType'] = NotImplemented\na['SliceType'] = slice(1)\na['UnboundMethodType'] = _class._method #XXX: works when not imported!\na['TextWrapperType'] = open(os.devnull, 'r') # same as mode='w','w+','r+'\na['BufferedRandomType'] = open(os.devnull, 'r+b') # same as mode='w+b'\na['BufferedReaderType'] = open(os.devnull, 'rb') # (default: buffering=-1)\na['BufferedWriterType'] = open(os.devnull, 'wb')\ntry: # oddities: deprecated\n    from _pyio import open as _open\n    a['PyTextWrapperType'] = _open(os.devnull, 'r', buffering=-1)\n    a['PyBufferedRandomType'] = _open(os.devnull, 'r+b', buffering=-1)\n    a['PyBufferedReaderType'] = _open(os.devnull, 'rb', buffering=-1)\n    a['PyBufferedWriterType'] = _open(os.devnull, 'wb', buffering=-1)\nexcept ImportError:\n    pass\n# other (concrete) object types\nif PY3:\n    d['CellType'] = (_lambda)(0).__closure__[0]\n    a['XRangeType'] = _xrange = range(1)\nelse:\n    d['CellType'] = (_lambda)(0).func_closure[0]\n    a['XRangeType'] = _xrange = xrange(1)\nif not IS_PYPY:\n    d['MethodDescriptorType'] = type.__dict__['mro']\n    d['WrapperDescriptorType'] = type.__repr__\n    a['WrapperDescriptorType2'] = type.__dict__['__module__']\n    d['ClassMethodDescriptorType'] = type.__dict__['__prepare__' if PY3 else 'mro']\n# built-in functions (CH 2)\nif PY3 or IS_PYPY: \n    _methodwrap = (1).__lt__\nelse: \n    _methodwrap = (1).__cmp__\nd['MethodWrapperType'] = _methodwrap\na['StaticMethodType'] = staticmethod(_method)\na['ClassMethodType'] = classmethod(_method)\na['PropertyType'] = property()\nd['SuperType'] = super(Exception, _exception)\n# string services (CH 7)\nif PY3: \n    _in = _bytes\nelse: \n    _in = _str\na['InputType'] = _cstrI = StringIO(_in)\na['OutputType'] = _cstrO = StringIO()\n# data types (CH 8)\na['WeakKeyDictionaryType'] = weakref.WeakKeyDictionary()\na['WeakValueDictionaryType'] = weakref.WeakValueDictionary()\na['ReferenceType'] = weakref.ref(_instance)\na['DeadReferenceType'] = weakref.ref(_class())\na['ProxyType'] = weakref.proxy(_instance)\na['DeadProxyType'] = weakref.proxy(_class())\na['CallableProxyType'] = weakref.proxy(_instance2)\na['DeadCallableProxyType'] = weakref.proxy(_class2())\na['QueueType'] = Queue.Queue()\n# numeric and mathematical types (CH 9)\nd['PartialType'] = functools.partial(int,base=2)\nif PY3:\n    a['IzipType'] = zip('0','1')\nelse:\n    a['IzipType'] = itertools.izip('0','1')\na['ChainType'] = itertools.chain('0','1')\nd['ItemGetterType'] = operator.itemgetter(0)\nd['AttrGetterType'] = operator.attrgetter('__repr__')\n# file and directory access (CH 10)\nif PY3: _fileW = _cstrO\nelse: _fileW = _tmpf\n# data persistence (CH 11)\nif HAS_ALL:\n    a['ConnectionType'] = _conn = sqlite3.connect(':memory:')\n    a['CursorType'] = _conn.cursor()\na['ShelveType'] = shelve.Shelf({})\n# data compression and archiving (CH 12)\nif HAS_ALL:\n    if (hex(sys.hexversion) < '0x2070ef0') or PY3:\n        a['BZ2FileType'] = bz2.BZ2File(os.devnull) #FIXME: fail >= 3.3, 2.7.14\n    a['BZ2CompressorType'] = bz2.BZ2Compressor()\n    a['BZ2DecompressorType'] = bz2.BZ2Decompressor()\n#a['ZipFileType'] = _zip = zipfile.ZipFile(os.devnull,'w') #FIXME: fail >= 3.2\n#_zip.write(_tempfile,'x') [causes annoying warning/error printed on import]\n#a['ZipInfoType'] = _zip.getinfo('x')\na['TarFileType'] = tarfile.open(fileobj=_fileW,mode='w')\n# file formats (CH 13)\na['DialectType'] = csv.get_dialect('excel')\na['PackerType'] = xdrlib.Packer()\n# optional operating system services (CH 16)\na['LockType'] = threading.Lock()\na['RLockType'] = threading.RLock()\n# generic operating system services (CH 15) # also closed/open and r/w/etc...\na['NamedLoggerType'] = _logger = logging.getLogger(__name__) #FIXME: fail >= 3.2 and <= 2.6\n#a['FrozenModuleType'] = __hello__ #FIXME: prints \"Hello world...\"\n# interprocess communication (CH 17)\nif PY3:\n    a['SocketType'] = _socket = socket.socket() #FIXME: fail >= 3.3\n    a['SocketPairType'] = socket.socketpair()[0] #FIXME: fail >= 3.3\nelse:\n    a['SocketType'] = _socket = socket.socket()\n    a['SocketPairType'] = _socket._sock\n# python runtime services (CH 27)\nif PY3:\n    a['GeneratorContextManagerType'] = contextlib.contextmanager(max)([1])\nelse:\n    a['GeneratorContextManagerType'] = contextlib.GeneratorContextManager(max)\n\ntry: # ipython\n    __IPYTHON__ is True # is ipython\nexcept NameError:\n    # built-in constants (CH 4)\n    a['QuitterType'] = quit\n    d['ExitType'] = a['QuitterType']\ntry: # numpy #FIXME: slow... 0.05 to 0.1 sec to import numpy\n    from numpy import ufunc as _numpy_ufunc\n    from numpy import array as _numpy_array\n    from numpy import int32 as _numpy_int32\n    a['NumpyUfuncType'] = _numpy_ufunc\n    a['NumpyArrayType'] = _numpy_array\n    a['NumpyInt32Type'] = _numpy_int32\nexcept ImportError:\n    pass\ntry: # python 2.6\n    # numeric and mathematical types (CH 9)\n    a['ProductType'] = itertools.product('0','1')\n    # generic operating system services (CH 15)\n    a['FileHandlerType'] = logging.FileHandler(os.devnull) #FIXME: fail >= 3.2 and <= 2.6\n    a['RotatingFileHandlerType'] = logging.handlers.RotatingFileHandler(os.devnull)\n    a['SocketHandlerType'] = logging.handlers.SocketHandler('localhost',514)\n    a['MemoryHandlerType'] = logging.handlers.MemoryHandler(1)\nexcept AttributeError:\n    pass\ntry: # python 2.7\n    # data types (CH 8)\n    a['WeakSetType'] = weakref.WeakSet() # 2.7\n#   # generic operating system services (CH 15) [errors when dill is imported]\n#   a['ArgumentParserType'] = _parser = argparse.ArgumentParser('PROG')\n#   a['NamespaceType'] = _parser.parse_args() # pickle ok\n#   a['SubParsersActionType'] = _parser.add_subparsers()\n#   a['MutuallyExclusiveGroupType'] = _parser.add_mutually_exclusive_group()\n#   a['ArgumentGroupType'] = _parser.add_argument_group()\nexcept AttributeError:\n    pass\n\n# -- dill fails in some versions below here ---------------------------------\n# types module (part of CH 8)\na['FileType'] = open(os.devnull, 'rb', buffering=0) # same 'wb','wb+','rb+'\n# FIXME: FileType fails >= 3.1\n# built-in functions (CH 2)\na['ListIteratorType'] = iter(_list) # empty vs non-empty FIXME: fail < 3.2\na['TupleIteratorType']= iter(_tuple) # empty vs non-empty FIXME: fail < 3.2\na['XRangeIteratorType'] = iter(_xrange) # empty vs non-empty FIXME: fail < 3.2\n# data types (CH 8)\na['PrettyPrinterType'] = pprint.PrettyPrinter() #FIXME: fail >= 3.2 and == 2.5\n# numeric and mathematical types (CH 9)\na['CycleType'] = itertools.cycle('0') #FIXME: fail < 3.2\n# file and directory access (CH 10)\na['TemporaryFileType'] = _tmpf #FIXME: fail >= 3.2 and == 2.5\n# data compression and archiving (CH 12)\na['GzipFileType'] = gzip.GzipFile(fileobj=_fileW) #FIXME: fail > 3.2 and <= 2.6\n# generic operating system services (CH 15)\na['StreamHandlerType'] = logging.StreamHandler() #FIXME: fail >= 3.2 and == 2.5\ntry: # python 2.6\n    # numeric and mathematical types (CH 9)\n    a['PermutationsType'] = itertools.permutations('0') #FIXME: fail < 3.2\n    a['CombinationsType'] = itertools.combinations('0',1) #FIXME: fail < 3.2\nexcept AttributeError:\n    pass\ntry: # python 2.7\n    # numeric and mathematical types (CH 9)\n    a['RepeatType'] = itertools.repeat(0) #FIXME: fail < 3.2\n    a['CompressType'] = itertools.compress('0',[1]) #FIXME: fail < 3.2\n    #XXX: ...and etc\nexcept AttributeError:\n    pass\n\n# -- dill fails on all below here -------------------------------------------\n# types module (part of CH 8)\nx['GeneratorType'] = _generator = _function(1) #XXX: priority\nx['FrameType'] = _generator.gi_frame #XXX: inspect.currentframe()\nx['TracebackType'] = _function2()[1] #(see: inspect.getouterframes,getframeinfo)\n# other (concrete) object types\n# (also: Capsule / CObject ?)\n# built-in functions (CH 2)\nx['SetIteratorType'] = iter(_set) #XXX: empty vs non-empty\n# built-in types (CH 5)\nif PY3:\n    x['DictionaryItemIteratorType'] = iter(type.__dict__.items())\n    x['DictionaryKeyIteratorType'] = iter(type.__dict__.keys())\n    x['DictionaryValueIteratorType'] = iter(type.__dict__.values())\nelse:\n    x['DictionaryItemIteratorType'] = type.__dict__.iteritems()\n    x['DictionaryKeyIteratorType'] = type.__dict__.iterkeys()\n    x['DictionaryValueIteratorType'] = type.__dict__.itervalues()\n# string services (CH 7)\nx['StructType'] = struct.Struct('c')\nx['CallableIteratorType'] = _srepattern.finditer('')\nx['SREMatchType'] = _srepattern.match('')\nx['SREScannerType'] = _srepattern.scanner('')\nx['StreamReader'] = codecs.StreamReader(_cstrI) #XXX: ... and etc\n# python object persistence (CH 11)\n# x['DbShelveType'] = shelve.open('foo','n')#,protocol=2) #XXX: delete foo\nif HAS_ALL:\n    x['DbmType'] = dbm.open(_tempfile,'n')\n# x['DbCursorType'] = _dbcursor = anydbm.open('foo','n') #XXX: delete foo\n# x['DbType'] = _dbcursor.db\n# data compression and archiving (CH 12)\nx['ZlibCompressType'] = zlib.compressobj()\nx['ZlibDecompressType'] = zlib.decompressobj()\n# file formats (CH 13)\nx['CSVReaderType'] = csv.reader(_cstrI)\nx['CSVWriterType'] = csv.writer(_cstrO)\nx['CSVDictReaderType'] = csv.DictReader(_cstrI)\nx['CSVDictWriterType'] = csv.DictWriter(_cstrO,{})\n# cryptographic services (CH 14)\nx['HashType'] = hashlib.md5()\nif (hex(sys.hexversion) < '0x30800a1'):\n    x['HMACType'] = hmac.new(_in)\nelse:\n    x['HMACType'] = hmac.new(_in, digestmod='md5')\n# generic operating system services (CH 15)\nif HAS_CURSES: pass\n    #x['CursesWindowType'] = _curwin = curses.initscr() #FIXME: messes up tty\n    #x['CursesTextPadType'] = textpad.Textbox(_curwin)\n    #x['CursesPanelType'] = panel.new_panel(_curwin)\nif HAS_CTYPES:\n    x['CCharPType'] = ctypes.c_char_p()\n    x['CWCharPType'] = ctypes.c_wchar_p()\n    x['CVoidPType'] = ctypes.c_void_p()\n    if sys.platform[:3] == 'win':\n        x['CDLLType'] = _cdll = ctypes.cdll.msvcrt\n    else:\n        x['CDLLType'] = _cdll = ctypes.CDLL(None)\n    if not IS_PYPY:\n        x['PyDLLType'] = _pydll = ctypes.pythonapi\n    x['FuncPtrType'] = _cdll._FuncPtr()\n    x['CCharArrayType'] = ctypes.create_string_buffer(1)\n    x['CWCharArrayType'] = ctypes.create_unicode_buffer(1)\n    x['CParamType'] = ctypes.byref(_cchar)\n    x['LPCCharType'] = ctypes.pointer(_cchar)\n    x['LPCCharObjType'] = _lpchar = ctypes.POINTER(ctypes.c_char)\n    x['NullPtrType'] = _lpchar()\n    x['NullPyObjectType'] = ctypes.py_object()\n    x['PyObjectType'] = ctypes.py_object(lambda :None)\n    x['FieldType'] = _field = _Struct._field\n    x['CFUNCTYPEType'] = _cfunc = ctypes.CFUNCTYPE(ctypes.c_char)\n    x['CFunctionType'] = _cfunc(str)\ntry: # python 2.6\n    # numeric and mathematical types (CH 9)\n    x['MethodCallerType'] = operator.methodcaller('mro') # 2.6\nexcept AttributeError:\n    pass\ntry: # python 2.7\n    # built-in types (CH 5)\n    x['MemoryType'] = memoryview(_in) # 2.7\n    x['MemoryType2'] = memoryview(bytearray(_in)) # 2.7\n    if PY3:\n        x['DictItemsType'] = _dict.items() # 2.7\n        x['DictKeysType'] = _dict.keys() # 2.7\n        x['DictValuesType'] = _dict.values() # 2.7\n    else:\n        x['DictItemsType'] = _dict.viewitems() # 2.7\n        x['DictKeysType'] = _dict.viewkeys() # 2.7\n        x['DictValuesType'] = _dict.viewvalues() # 2.7\n    # generic operating system services (CH 15)\n    x['RawTextHelpFormatterType'] = argparse.RawTextHelpFormatter('PROG')\n    x['RawDescriptionHelpFormatterType'] = argparse.RawDescriptionHelpFormatter('PROG')\n    x['ArgDefaultsHelpFormatterType'] = argparse.ArgumentDefaultsHelpFormatter('PROG')\nexcept NameError:\n    pass\ntry: # python 2.7 (and not 3.1)\n    x['CmpKeyType'] = _cmpkey = functools.cmp_to_key(_methodwrap) # 2.7, >=3.2\n    x['CmpKeyObjType'] = _cmpkey('0') #2.7, >=3.2\nexcept AttributeError:\n    pass\nif PY3: # oddities: removed, etc\n    x['BufferType'] = x['MemoryType']\nelse:\n    x['BufferType'] = buffer('')\n\n# -- cleanup ----------------------------------------------------------------\na.update(d) # registered also succeed\nif sys.platform[:3] == 'win':\n    os.close(_filedescrip) # required on win32\nos.remove(_tempfile)\n\n\n# EOF\n"
            },
            "detect": {
                "type": "module",
                "extension": "py",
                "code": "#!/usr/bin/env python\n#\n# Author: Mike McKerns (mmckerns @caltech and @uqfoundation)\n# Copyright (c) 2008-2016 California Institute of Technology.\n# Copyright (c) 2016-2020 The Uncertainty Quantification Foundation.\n# License: 3-clause BSD.  The full license text is available at:\n#  - https://github.com/uqfoundation/dill/blob/master/LICENSE\n\"\"\"\nMethods for detecting objects leading to pickling failures.\n\"\"\"\n\nimport dis\nfrom inspect import ismethod, isfunction, istraceback, isframe, iscode\nfrom .pointers import parent, reference, at, parents, children\n\nfrom ._dill import _trace as trace\nfrom ._dill import PY3\n\n__all__ = ['baditems','badobjects','badtypes','code','errors','freevars',\n           'getmodule','globalvars','nestedcode','nestedglobals','outermost',\n           'referredglobals','referrednested','trace','varnames']\n\ndef getmodule(object, _filename=None, force=False):\n    \"\"\"get the module of the object\"\"\"\n    from inspect import getmodule as getmod\n    module = getmod(object, _filename)\n    if module or not force: return module\n    if PY3: builtins = 'builtins'\n    else: builtins = '__builtin__'\n    builtins = __import__(builtins)\n    from .source import getname\n    name = getname(object, force=True)\n    return builtins if name in vars(builtins).keys() else None\n\ndef outermost(func): # is analogous to getsource(func,enclosing=True)\n    \"\"\"get outermost enclosing object (i.e. the outer function in a closure)\n\n    NOTE: this is the object-equivalent of getsource(func, enclosing=True)\n    \"\"\"\n    if PY3:\n        if ismethod(func):\n            _globals = func.__func__.__globals__ or {}\n        elif isfunction(func):\n            _globals = func.__globals__ or {}\n        else:\n            return #XXX: or raise? no matches\n        _globals = _globals.items()\n    else:\n        if ismethod(func):\n            _globals = func.im_func.func_globals or {}\n        elif isfunction(func):\n            _globals = func.func_globals or {}\n        else:\n            return #XXX: or raise? no matches\n        _globals = _globals.iteritems()\n    # get the enclosing source\n    from .source import getsourcelines\n    try: lines,lnum = getsourcelines(func, enclosing=True)\n    except: #TypeError, IOError\n        lines,lnum = [],None\n    code = ''.join(lines)\n    # get all possible names,objects that are named in the enclosing source\n    _locals = ((name,obj) for (name,obj) in _globals if name in code)\n    # now only save the objects that generate the enclosing block\n    for name,obj in _locals: #XXX: don't really need 'name'\n        try:\n            if getsourcelines(obj) == (lines,lnum): return obj\n        except: #TypeError, IOError\n            pass\n    return #XXX: or raise? no matches\n\ndef nestedcode(func, recurse=True): #XXX: or return dict of {co_name: co} ?\n    \"\"\"get the code objects for any nested functions (e.g. in a closure)\"\"\"\n    func = code(func)\n    if not iscode(func): return [] #XXX: or raise? no matches\n    nested = set()\n    for co in func.co_consts:\n        if co is None: continue\n        co = code(co)\n        if co:\n            nested.add(co)\n            if recurse: nested |= set(nestedcode(co, recurse=True))\n    return list(nested)\n\ndef code(func):\n    '''get the code object for the given function or method\n\n    NOTE: use dill.source.getsource(CODEOBJ) to get the source code\n    '''\n    if PY3:\n        im_func = '__func__'\n        func_code = '__code__'\n    else:\n        im_func = 'im_func'\n        func_code = 'func_code'\n    if ismethod(func): func = getattr(func, im_func)\n    if isfunction(func): func = getattr(func, func_code)\n    if istraceback(func): func = func.tb_frame\n    if isframe(func): func = func.f_code\n    if iscode(func): return func\n    return\n\n#XXX: ugly: parse dis.dis for name after \"<code object\" in line and in globals?\ndef referrednested(func, recurse=True): #XXX: return dict of {__name__: obj} ?\n    \"\"\"get functions defined inside of func (e.g. inner functions in a closure)\n\n    NOTE: results may differ if the function has been executed or not.\n    If len(nestedcode(func)) > len(referrednested(func)), try calling func().\n    If possible, python builds code objects, but delays building functions\n    until func() is called.\n    \"\"\"\n    if PY3:\n        att1 = '__code__'\n        att0 = '__func__'\n    else:\n        att1 = 'func_code' # functions\n        att0 = 'im_func'   # methods\n\n    import gc\n    funcs = set()\n    # get the code objects, and try to track down by referrence\n    for co in nestedcode(func, recurse):\n        # look for function objects that refer to the code object\n        for obj in gc.get_referrers(co):\n            # get methods\n            _ = getattr(obj, att0, None) # ismethod\n            if getattr(_, att1, None) is co: funcs.add(obj)\n            # get functions\n            elif getattr(obj, att1, None) is co: funcs.add(obj)\n            # get frame objects\n            elif getattr(obj, 'f_code', None) is co: funcs.add(obj)\n            # get code objects\n            elif hasattr(obj, 'co_code') and obj is co: funcs.add(obj)\n#     frameobjs => func.func_code.co_varnames not in func.func_code.co_cellvars\n#     funcobjs => func.func_code.co_cellvars not in func.func_code.co_varnames\n#     frameobjs are not found, however funcobjs are...\n#     (see: test_mixins.quad ... and test_mixins.wtf)\n#     after execution, code objects get compiled, and then may be found by gc\n    return list(funcs)\n\n\ndef freevars(func):\n    \"\"\"get objects defined in enclosing code that are referred to by func\n\n    returns a dict of {name:object}\"\"\"\n    if PY3:\n        im_func = '__func__'\n        func_code = '__code__'\n        func_closure = '__closure__'\n    else:\n        im_func = 'im_func'\n        func_code = 'func_code'\n        func_closure = 'func_closure'\n    if ismethod(func): func = getattr(func, im_func)\n    if isfunction(func):\n        closures = getattr(func, func_closure) or ()\n        func = getattr(func, func_code).co_freevars # get freevars\n    else:\n        return {}\n    return dict((name,c.cell_contents) for (name,c) in zip(func,closures))\n\n# thanks to Davies Liu for recursion of globals\ndef nestedglobals(func, recurse=True):\n    \"\"\"get the names of any globals found within func\"\"\"\n    func = code(func)\n    if func is None: return list()\n    from .temp import capture\n    names = set()\n    with capture('stdout') as out:\n        dis.dis(func) #XXX: dis.dis(None) disassembles last traceback\n    for line in out.getvalue().splitlines():\n        if '_GLOBAL' in line:\n            name = line.split('(')[-1].split(')')[0]\n            names.add(name)\n    for co in getattr(func, 'co_consts', tuple()):\n        if co and recurse and iscode(co):\n            names.update(nestedglobals(co, recurse=True))\n    return list(names)\n\ndef referredglobals(func, recurse=True, builtin=False):\n    \"\"\"get the names of objects in the global scope referred to by func\"\"\"\n    return globalvars(func, recurse, builtin).keys()\n\ndef globalvars(func, recurse=True, builtin=False):\n    \"\"\"get objects defined in global scope that are referred to by func\n\n    return a dict of {name:object}\"\"\"\n    if PY3:\n        im_func = '__func__'\n        func_code = '__code__'\n        func_globals = '__globals__'\n        func_closure = '__closure__'\n    else:\n        im_func = 'im_func'\n        func_code = 'func_code'\n        func_globals = 'func_globals'\n        func_closure = 'func_closure'\n    if ismethod(func): func = getattr(func, im_func)\n    if isfunction(func):\n        globs = vars(getmodule(sum)).copy() if builtin else {}\n        # get references from within closure\n        orig_func, func = func, set()\n        for obj in getattr(orig_func, func_closure) or {}:\n            _vars = globalvars(obj.cell_contents, recurse, builtin) or {}\n            func.update(_vars) #XXX: (above) be wary of infinte recursion?\n            globs.update(_vars)\n        # get globals\n        globs.update(getattr(orig_func, func_globals) or {})\n        # get names of references\n        if not recurse:\n            func.update(getattr(orig_func, func_code).co_names)\n        else:\n            func.update(nestedglobals(getattr(orig_func, func_code)))\n            # find globals for all entries of func\n            for key in func.copy(): #XXX: unnecessary...?\n                nested_func = globs.get(key)\n                if nested_func is orig_func:\n                   #func.remove(key) if key in func else None\n                    continue  #XXX: globalvars(func, False)?\n                func.update(globalvars(nested_func, True, builtin))\n    elif iscode(func):\n        globs = vars(getmodule(sum)).copy() if builtin else {}\n       #globs.update(globals())\n        if not recurse:\n            func = func.co_names # get names\n        else:\n            orig_func = func.co_name # to stop infinite recursion\n            func = set(nestedglobals(func))\n            # find globals for all entries of func\n            for key in func.copy(): #XXX: unnecessary...?\n                if key is orig_func:\n                   #func.remove(key) if key in func else None\n                    continue  #XXX: globalvars(func, False)?\n                nested_func = globs.get(key)\n                func.update(globalvars(nested_func, True, builtin))\n    else:\n        return {}\n    #NOTE: if name not in func_globals, then we skip it...\n    return dict((name,globs[name]) for name in func if name in globs)\n\n\ndef varnames(func):\n    \"\"\"get names of variables defined by func\n\n    returns a tuple (local vars, local vars referrenced by nested functions)\"\"\"\n    func = code(func)\n    if not iscode(func):\n        return () #XXX: better ((),())? or None?\n    return func.co_varnames, func.co_cellvars\n\n\ndef baditems(obj, exact=False, safe=False): #XXX: obj=globals() ?\n    \"\"\"get items in object that fail to pickle\"\"\"\n    if not hasattr(obj,'__iter__'): # is not iterable\n        return [j for j in (badobjects(obj,0,exact,safe),) if j is not None]\n    obj = obj.values() if getattr(obj,'values',None) else obj\n    _obj = [] # can't use a set, as items may be unhashable\n    [_obj.append(badobjects(i,0,exact,safe)) for i in obj if i not in _obj]\n    return [j for j in _obj if j is not None]\n\n\ndef badobjects(obj, depth=0, exact=False, safe=False):\n    \"\"\"get objects that fail to pickle\"\"\"\n    from dill import pickles\n    if not depth:\n        if pickles(obj,exact,safe): return None\n        return obj\n    return dict(((attr, badobjects(getattr(obj,attr),depth-1,exact,safe)) \\\n           for attr in dir(obj) if not pickles(getattr(obj,attr),exact,safe)))\n\ndef badtypes(obj, depth=0, exact=False, safe=False):\n    \"\"\"get types for objects that fail to pickle\"\"\"\n    from dill import pickles\n    if not depth:\n        if pickles(obj,exact,safe): return None\n        return type(obj)\n    return dict(((attr, badtypes(getattr(obj,attr),depth-1,exact,safe)) \\\n           for attr in dir(obj) if not pickles(getattr(obj,attr),exact,safe)))\n\ndef errors(obj, depth=0, exact=False, safe=False):\n    \"\"\"get errors for objects that fail to pickle\"\"\"\n    from dill import pickles, copy\n    if not depth:\n        try:\n            pik = copy(obj)\n            if exact:\n                assert pik == obj, \\\n                    \"Unpickling produces %s instead of %s\" % (pik,obj)\n            assert type(pik) == type(obj), \\\n                \"Unpickling produces %s instead of %s\" % (type(pik),type(obj))\n            return None\n        except Exception:\n            import sys\n            return sys.exc_info()[1]\n    _dict = {}\n    for attr in dir(obj):\n        try:\n            _attr = getattr(obj,attr)\n        except Exception:\n            import sys\n            _dict[attr] = sys.exc_info()[1]\n            continue\n        if not pickles(_attr,exact,safe):\n            _dict[attr] = errors(_attr,depth-1,exact,safe)\n    return _dict\n\n\n# EOF\n"
            },
            "info": {
                "type": "module",
                "extension": "py",
                "code": "# THIS FILE GENERATED FROM SETUP.PY\nthis_version = '0.3.3'\nstable_version = '0.3.3'\nreadme = '''-----------------------------\ndill: serialize all of python\n-----------------------------\n\nAbout Dill\n==========\n\n``dill`` extends python's ``pickle`` module for serializing and de-serializing\npython objects to the majority of the built-in python types. Serialization\nis the process of converting an object to a byte stream, and the inverse\nof which is converting a byte stream back to a python object hierarchy.\n\n``dill`` provides the user the same interface as the ``pickle`` module, and\nalso includes some additional features. In addition to pickling python\nobjects, ``dill`` provides the ability to save the state of an interpreter\nsession in a single command.  Hence, it would be feasable to save a\ninterpreter session, close the interpreter, ship the pickled file to\nanother computer, open a new interpreter, unpickle the session and\nthus continue from the 'saved' state of the original interpreter\nsession.\n\n``dill`` can be used to store python objects to a file, but the primary\nusage is to send python objects across the network as a byte stream.\n``dill`` is quite flexible, and allows arbitrary user defined classes\nand functions to be serialized.  Thus ``dill`` is not intended to be\nsecure against erroneously or maliciously constructed data. It is\nleft to the user to decide whether the data they unpickle is from\na trustworthy source.\n\n``dill`` is part of ``pathos``, a python framework for heterogeneous computing.\n``dill`` is in active development, so any user feedback, bug reports, comments,\nor suggestions are highly appreciated.  A list of issues is located at https://github.com/uqfoundation/dill/issues, with a legacy list maintained at https://uqfoundation.github.io/pathos-issues.html.\n\n\nMajor Features\n==============\n\n``dill`` can pickle the following standard types:\n\n    - none, type, bool, int, long, float, complex, str, unicode,\n    - tuple, list, dict, file, buffer, builtin,\n    - both old and new style classes,\n    - instances of old and new style classes,\n    - set, frozenset, array, functions, exceptions\n\n``dill`` can also pickle more 'exotic' standard types:\n\n    - functions with yields, nested functions, lambdas,\n    - cell, method, unboundmethod, module, code, methodwrapper,\n    - dictproxy, methoddescriptor, getsetdescriptor, memberdescriptor,\n    - wrapperdescriptor, xrange, slice,\n    - notimplemented, ellipsis, quit\n\n``dill`` cannot yet pickle these standard types:\n\n    - frame, generator, traceback\n\n``dill`` also provides the capability to:\n\n    - save and load python interpreter sessions\n    - save and extract the source code from functions and classes\n    - interactively diagnose pickling errors\n\n\nCurrent Release\n===============\n\nThis documentation is for version ``dill-0.3.3``.\n\nThe latest released version of ``dill`` is available from:\n\n    https://pypi.org/project/dill\n\n``dill`` is distributed under a 3-clause BSD license.\n\n    >>> import dill\n    >>> dill.license()\n\n\nDevelopment Version \n===================\n\nYou can get the latest development version with all the shiny new features at:\n\n    https://github.com/uqfoundation\n\nIf you have a new contribution, please submit a pull request.\n\n\nInstallation\n============\n\n``dill`` is packaged to install from source, so you must\ndownload the tarball, unzip, and run the installer::\n\n    [download]\n    $ tar -xvzf dill-0.3.3.tar.gz\n    $ cd dill-0.3.3\n    $ python setup py build\n    $ python setup py install\n\nYou will be warned of any missing dependencies and/or settings\nafter you run the \"build\" step above. \n\nAlternately, ``dill`` can be installed with ``pip`` or ``easy_install``::\n\n    $ pip install dill\n\n\nRequirements\n============\n\n``dill`` requires:\n\n    - ``python``, **version == 2.7** or **version >= 3.5**, or ``pypy``\n\nOptional requirements:\n\n    - ``setuptools``, **version >= 0.6**\n    - ``pyreadline``, **version >= 1.7.1** (on windows)\n    - ``objgraph``, **version >= 1.7.2**\n\n\nMore Information\n================\n\nProbably the best way to get started is to look at the documentation at\nhttp://dill.rtfd.io. Also see ``dill.tests`` for a set of scripts that\ndemonstrate how ``dill`` can serialize different python objects. You can\nrun the test suite with ``python -m dill.tests``. The contents of any\npickle file can be examined with ``undill``.  As ``dill`` conforms to\nthe ``pickle`` interface, the examples and documentation found at\nhttp://docs.python.org/library/pickle.html also apply to ``dill``\nif one will ``import dill as pickle``. The source code is also generally\nwell documented, so further questions may be resolved by inspecting the\ncode itself. Please feel free to submit a ticket on github, or ask a\nquestion on stackoverflow (**@Mike McKerns**).\nIf you would like to share how you use ``dill`` in your work, please send\nan email (to **mmckerns at uqfoundation dot org**).\n\n\nCitation\n========\n\nIf you use ``dill`` to do research that leads to publication, we ask that you\nacknowledge use of ``dill`` by citing the following in your publication::\n\n    M.M. McKerns, L. Strand, T. Sullivan, A. Fang, M.A.G. Aivazis,\n    \"Building a framework for predictive science\", Proceedings of\n    the 10th Python in Science Conference, 2011;\n    http://arxiv.org/pdf/1202.1056\n\n    Michael McKerns and Michael Aivazis,\n    \"pathos: a framework for heterogeneous computing\", 2010- ;\n    https://uqfoundation.github.io/pathos.html\n\nPlease see https://uqfoundation.github.io/pathos.html or\nhttp://arxiv.org/pdf/1202.1056 for further information.\n\n'''\nlicense = '''Copyright (c) 2004-2016 California Institute of Technology.\nCopyright (c) 2016-2020 The Uncertainty Quantification Foundation.\nAll rights reserved.\n\nThis software is available subject to the conditions and terms laid\nout below. By downloading and using this software you are agreeing\nto the following conditions.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions\nare met::\n\n    - Redistribution of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n\n    - Redistribution in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentations and/or other materials provided with the distribution.\n\n    - Neither the names of the copyright holders nor the names of any of\n      the contributors may be used to endorse or promote products derived\n      from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\nTO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR\nCONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\nEXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\nPROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;\nOR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\nWHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR\nOTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\nADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n'''\n"
            },
            "objtypes": {
                "type": "module",
                "extension": "py",
                "code": "#!/usr/bin/env python\n#\n# Author: Mike McKerns (mmckerns @caltech and @uqfoundation)\n# Copyright (c) 2008-2016 California Institute of Technology.\n# Copyright (c) 2016-2020 The Uncertainty Quantification Foundation.\n# License: 3-clause BSD.  The full license text is available at:\n#  - https://github.com/uqfoundation/dill/blob/master/LICENSE\n\"\"\"\nall Python Standard Library object types (currently: CH 1-15 @ 2.7)\nand some other common object types (i.e. numpy.ndarray)\n\nto load more objects and types, use dill.load_types()\n\"\"\"\n\n# non-local import of dill.objects\nfrom dill import objects\nfor _type in objects.keys():\n    exec(\"%s = type(objects['%s'])\" % (_type,_type))\n    \ndel objects\ntry:\n    del _type\nexcept NameError:\n    pass\n"
            },
            "pointers": {
                "type": "module",
                "extension": "py",
                "code": "#!/usr/bin/env python\n#\n# Author: Mike McKerns (mmckerns @caltech and @uqfoundation)\n# Copyright (c) 2008-2016 California Institute of Technology.\n# Copyright (c) 2016-2020 The Uncertainty Quantification Foundation.\n# License: 3-clause BSD.  The full license text is available at:\n#  - https://github.com/uqfoundation/dill/blob/master/LICENSE\n\n__all__ = ['parent', 'reference', 'at', 'parents', 'children']\n\nimport gc\nimport sys\n\nfrom ._dill import _proxy_helper as reference\nfrom ._dill import _locate_object as at\n\ndef parent(obj, objtype, ignore=()):\n    \"\"\"\n>>> listiter = iter([4,5,6,7])\n>>> obj = parent(listiter, list)\n>>> obj == [4,5,6,7]  # actually 'is', but don't have handle any longer\nTrue\n\nNOTE: objtype can be a single type (e.g. int or list) or a tuple of types.\n\nWARNING: if obj is a sequence (e.g. list), may produce unexpected results.\nParent finds *one* parent (e.g. the last member of the sequence).\n    \"\"\"\n    depth = 1 #XXX: always looking for the parent (only, right?)\n    chain = parents(obj, objtype, depth, ignore)\n    parent = chain.pop()\n    if parent is obj:\n        return None\n    return parent\n\n\ndef parents(obj, objtype, depth=1, ignore=()): #XXX: objtype=object ?\n    \"\"\"Find the chain of referents for obj. Chain will end with obj.\n\n    objtype: an object type or tuple of types to search for\n    depth: search depth (e.g. depth=2 is 'grandparents')\n    ignore: an object or tuple of objects to ignore in the search\n    \"\"\"\n    edge_func = gc.get_referents # looking for refs, not back_refs\n    predicate = lambda x: isinstance(x, objtype) # looking for parent type\n   #if objtype is None: predicate = lambda x: True #XXX: in obj.mro() ?\n    ignore = (ignore,) if not hasattr(ignore, '__len__') else ignore\n    ignore = (id(obj) for obj in ignore)\n    chain = find_chain(obj, predicate, edge_func, depth)[::-1]\n    #XXX: should pop off obj... ?\n    return chain\n\n\ndef children(obj, objtype, depth=1, ignore=()): #XXX: objtype=object ?\n    \"\"\"Find the chain of referrers for obj. Chain will start with obj.\n\n    objtype: an object type or tuple of types to search for\n    depth: search depth (e.g. depth=2 is 'grandchildren')\n    ignore: an object or tuple of objects to ignore in the search\n\n    NOTE: a common thing to ignore is all globals, 'ignore=(globals(),)'\n\n    NOTE: repeated calls may yield different results, as python stores\n    the last value in the special variable '_'; thus, it is often good\n    to execute something to replace '_' (e.g. >>> 1+1).\n    \"\"\"\n    edge_func = gc.get_referrers # looking for back_refs, not refs\n    predicate = lambda x: isinstance(x, objtype) # looking for child type\n   #if objtype is None: predicate = lambda x: True #XXX: in obj.mro() ?\n    ignore = (ignore,) if not hasattr(ignore, '__len__') else ignore\n    ignore = (id(obj) for obj in ignore)\n    chain = find_chain(obj, predicate, edge_func, depth, ignore)\n    #XXX: should pop off obj... ?\n    return chain\n\n\n# more generic helper function (cut-n-paste from objgraph)\n# Source at http://mg.pov.lt/objgraph/\n# Copyright (c) 2008-2010 Marius Gedminas <marius@pov.lt>\n# Copyright (c) 2010 Stefano Rivera <stefano@rivera.za.net>\n# Released under the MIT licence (see objgraph/objgrah.py)\n\ndef find_chain(obj, predicate, edge_func, max_depth=20, extra_ignore=()):\n    queue = [obj]\n    depth = {id(obj): 0}\n    parent = {id(obj): None}\n    ignore = set(extra_ignore)\n    ignore.add(id(extra_ignore))\n    ignore.add(id(queue))\n    ignore.add(id(depth))\n    ignore.add(id(parent))\n    ignore.add(id(ignore))\n    ignore.add(id(sys._getframe()))  # this function\n    ignore.add(id(sys._getframe(1))) # find_chain/find_backref_chain, likely\n    gc.collect()\n    while queue:\n        target = queue.pop(0)\n        if predicate(target):\n            chain = [target]\n            while parent[id(target)] is not None:\n                target = parent[id(target)]\n                chain.append(target)\n            return chain\n        tdepth = depth[id(target)]\n        if tdepth < max_depth:\n            referrers = edge_func(target)\n            ignore.add(id(referrers))\n            for source in referrers:\n                if id(source) in ignore:\n                    continue\n                if id(source) not in depth:\n                    depth[id(source)] = tdepth + 1\n                    parent[id(source)] = target\n                    queue.append(source)\n    return [obj] # not found\n\n\n# backward compatability\nrefobject = at\n\n\n# EOF\n"
            },
            "settings": {
                "type": "module",
                "extension": "py",
                "code": "#!/usr/bin/env python\n#\n# Author: Mike McKerns (mmckerns @caltech and @uqfoundation)\n# Copyright (c) 2008-2016 California Institute of Technology.\n# Copyright (c) 2016-2020 The Uncertainty Quantification Foundation.\n# License: 3-clause BSD.  The full license text is available at:\n#  - https://github.com/uqfoundation/dill/blob/master/LICENSE\n\"\"\"\nglobal settings for Pickler\n\"\"\"\n\ntry:\n    from pickle import DEFAULT_PROTOCOL\nexcept ImportError:\n    from pickle import HIGHEST_PROTOCOL as DEFAULT_PROTOCOL\n\nsettings = {\n   #'main' : None,\n    'protocol' : DEFAULT_PROTOCOL,\n    'byref' : False,\n   #'strictio' : False,\n    'fmode' : 0, #HANDLE_FMODE\n    'recurse' : False,\n    'ignore' : False,\n}\n\ndel DEFAULT_PROTOCOL\n\n"
            },
            "source": {
                "type": "module",
                "extension": "py",
                "code": "#!/usr/bin/env python\n#\n# Author: Mike McKerns (mmckerns @caltech and @uqfoundation)\n# Copyright (c) 2008-2016 California Institute of Technology.\n# Copyright (c) 2016-2020 The Uncertainty Quantification Foundation.\n# License: 3-clause BSD.  The full license text is available at:\n#  - https://github.com/uqfoundation/dill/blob/master/LICENSE\n#\n# inspired by inspect.py from Python-2.7.6\n# inspect.py author: 'Ka-Ping Yee <ping@lfw.org>'\n# inspect.py merged into original dill.source by Mike McKerns 4/13/14\n\"\"\"\nExtensions to python's 'inspect' module, which can be used\nto retrieve information from live python objects. The methods\ndefined in this module are augmented to facilitate access to \nsource code of interactively defined functions and classes,\nas well as provide access to source code for objects defined\nin a file.\n\"\"\"\n\n__all__ = ['findsource', 'getsourcelines', 'getsource', 'indent', 'outdent', \\\n           '_wrap', 'dumpsource', 'getname', '_namespace', 'getimport', \\\n           '_importable', 'importable','isdynamic', 'isfrommain']\n\nimport linecache\nimport re\nfrom inspect import (getblock, getfile, getmodule, getsourcefile, indentsize,\n                     isbuiltin, isclass, iscode, isframe, isfunction, ismethod,\n                     ismodule, istraceback)\nfrom tokenize import TokenError\n\nfrom ._dill import PY3\n\n\ndef isfrommain(obj):\n    \"check if object was built in __main__\"\n    module = getmodule(obj)\n    if module and module.__name__ == '__main__':\n        return True\n    return False\n\n\ndef isdynamic(obj):\n    \"check if object was built in the interpreter\"\n    try: file = getfile(obj)\n    except TypeError: file = None \n    if file == '<stdin>' and isfrommain(obj):\n        return True\n    return False\n\n\ndef _matchlambda(func, line):\n    \"\"\"check if lambda object 'func' matches raw line of code 'line'\"\"\"\n    from .detect import code as getcode\n    from .detect import freevars, globalvars, varnames\n    dummy = lambda : '__this_is_a_big_dummy_function__'\n    # process the line (removing leading whitespace, etc)\n    lhs,rhs = line.split('lambda ',1)[-1].split(\":\", 1) #FIXME: if !1 inputs\n    try: #FIXME: unsafe\n        _ = eval(\"lambda %s : %s\" % (lhs,rhs), globals(),locals())\n    except: _ = dummy\n    # get code objects, for comparison\n    _, code = getcode(_).co_code, getcode(func).co_code\n    # check if func is in closure\n    _f = [line.count(i) for i in freevars(func).keys()]\n    if not _f: # not in closure\n        # check if code matches\n        if _ == code: return True\n        return False\n    # weak check on freevars\n    if not all(_f): return False  #XXX: VERY WEAK\n    # weak check on varnames and globalvars\n    _f = varnames(func)\n    _f = [line.count(i) for i in _f[0]+_f[1]]\n    if _f and not all(_f): return False  #XXX: VERY WEAK\n    _f = [line.count(i) for i in globalvars(func).keys()]\n    if _f and not all(_f): return False  #XXX: VERY WEAK\n    # check if func is a double lambda\n    if (line.count('lambda ') > 1) and (lhs in freevars(func).keys()):\n        _lhs,_rhs = rhs.split('lambda ',1)[-1].split(\":\",1) #FIXME: if !1 inputs\n        try: #FIXME: unsafe\n            _f = eval(\"lambda %s : %s\" % (_lhs,_rhs), globals(),locals())\n        except: _f = dummy\n        # get code objects, for comparison\n        _, code = getcode(_f).co_code, getcode(func).co_code\n        if len(_) != len(code): return False\n        #NOTE: should be same code same order, but except for 't' and '\\x88'\n        _ = set((i,j) for (i,j) in zip(_,code) if i != j)\n        if len(_) != 1: return False #('t','\\x88')\n        return True\n    # check indentsize\n    if not indentsize(line): return False #FIXME: is this a good check???\n    # check if code 'pattern' matches\n    #XXX: or pattern match against dis.dis(code)? (or use uncompyle2?)\n    _ = _.split(_[0])  # 't' #XXX: remove matching values if starts the same?\n    _f = code.split(code[0])  # '\\x88'\n    #NOTE: should be same code different order, with different first element\n    _ = dict(re.match(r'([\\W\\D\\S])(.*)', _[i]).groups() for i in range(1,len(_)))\n    _f = dict(re.match(r'([\\W\\D\\S])(.*)', _f[i]).groups() for i in range(1,len(_f)))\n    if (_.keys() == _f.keys()) and (sorted(_.values()) == sorted(_f.values())):\n        return True\n    return False\n\n\ndef findsource(object):\n    \"\"\"Return the entire source file and starting line number for an object.\n    For interactively-defined objects, the 'file' is the interpreter's history.\n\n    The argument may be a module, class, method, function, traceback, frame,\n    or code object.  The source code is returned as a list of all the lines\n    in the file and the line number indexes a line in that list.  An IOError\n    is raised if the source code cannot be retrieved, while a TypeError is\n    raised for objects where the source code is unavailable (e.g. builtins).\"\"\"\n\n    module = getmodule(object)\n    try: file = getfile(module)\n    except TypeError: file = None \n    # use readline when working in interpreter (i.e. __main__ and not file)\n    if module and module.__name__ == '__main__' and not file:\n        try: \n            import readline\n            err = ''\n        except:\n            import sys\n            err = sys.exc_info()[1].args[0]\n            if sys.platform[:3] == 'win':\n                err += \", please install 'pyreadline'\"\n        if err:\n            raise IOError(err)\n        lbuf = readline.get_current_history_length()\n        lines = [readline.get_history_item(i)+'\\n' for i in range(1,lbuf)]\n    else:\n        try: # special handling for class instances\n            if not isclass(object) and isclass(type(object)): # __class__\n                file = getfile(module)        \n                sourcefile = getsourcefile(module)\n            else: # builtins fail with a TypeError\n                file = getfile(object)\n                sourcefile = getsourcefile(object)\n        except (TypeError, AttributeError): # fail with better error\n            file = getfile(object)\n            sourcefile = getsourcefile(object)\n        if not sourcefile and file[:1] + file[-1:] != '<>':\n            raise IOError('source code not available')\n        file = sourcefile if sourcefile else file\n\n        module = getmodule(object, file)\n        if module:\n            lines = linecache.getlines(file, module.__dict__)\n        else:\n            lines = linecache.getlines(file)\n\n    if not lines:\n        raise IOError('could not extract source code')\n\n    #FIXME: all below may fail if exec used (i.e. exec('f = lambda x:x') )\n    if ismodule(object):\n        return lines, 0\n\n    #NOTE: beneficial if search goes from end to start of buffer history\n    name = pat1 = obj = ''\n    pat2 = r'^(\\s*@)'\n#   pat1b = r'^(\\s*%s\\W*=)' % name #FIXME: finds 'f = decorate(f)', not exec\n    if ismethod(object):\n        name = object.__name__\n        if name == '<lambda>': pat1 = r'(.*(?<!\\w)lambda(:|\\s))'\n        else: pat1 = r'^(\\s*def\\s)'\n        if PY3: object = object.__func__\n        else: object = object.im_func\n    if isfunction(object):\n        name = object.__name__\n        if name == '<lambda>':\n            pat1 = r'(.*(?<!\\w)lambda(:|\\s))'\n            obj = object #XXX: better a copy?\n        else: pat1 = r'^(\\s*def\\s)'\n        if PY3: object = object.__code__\n        else: object = object.func_code\n    if istraceback(object):\n        object = object.tb_frame\n    if isframe(object):\n        object = object.f_code\n    if iscode(object):\n        if not hasattr(object, 'co_firstlineno'):\n            raise IOError('could not find function definition')\n        stdin = object.co_filename == '<stdin>'\n        if stdin:\n            lnum = len(lines) - 1 # can't get lnum easily, so leverage pat\n            if not pat1: pat1 = r'^(\\s*def\\s)|(.*(?<!\\w)lambda(:|\\s))|^(\\s*@)'\n        else:\n            lnum = object.co_firstlineno - 1\n            pat1 = r'^(\\s*def\\s)|(.*(?<!\\w)lambda(:|\\s))|^(\\s*@)'\n        pat1 = re.compile(pat1); pat2 = re.compile(pat2)\n       #XXX: candidate_lnum = [n for n in range(lnum) if pat1.match(lines[n])]\n        while lnum > 0: #XXX: won't find decorators in <stdin> ?\n            line = lines[lnum]\n            if pat1.match(line):\n                if not stdin: break # co_firstlineno does the job\n                if name == '<lambda>': # hackery needed to confirm a match\n                    if _matchlambda(obj, line): break\n                else: # not a lambda, just look for the name\n                    if name in line: # need to check for decorator...\n                        hats = 0\n                        for _lnum in range(lnum-1,-1,-1):\n                            if pat2.match(lines[_lnum]): hats += 1\n                            else: break\n                        lnum = lnum - hats\n                        break\n            lnum = lnum - 1\n        return lines, lnum\n\n    try: # turn instances into classes\n        if not isclass(object) and isclass(type(object)): # __class__\n            object = object.__class__ #XXX: sometimes type(class) is better?\n            #XXX: we don't find how the instance was built\n    except AttributeError: pass\n    if isclass(object):\n        name = object.__name__\n        pat = re.compile(r'^(\\s*)class\\s*' + name + r'\\b')\n        # make some effort to find the best matching class definition:\n        # use the one with the least indentation, which is the one\n        # that's most probably not inside a function definition.\n        candidates = []\n        for i in range(len(lines)-1,-1,-1):\n            match = pat.match(lines[i])\n            if match:\n                # if it's at toplevel, it's already the best one\n                if lines[i][0] == 'c':\n                    return lines, i\n                # else add whitespace to candidate list\n                candidates.append((match.group(1), i))\n        if candidates:\n            # this will sort by whitespace, and by line number,\n            # less whitespace first  #XXX: should sort high lnum before low\n            candidates.sort()\n            return lines, candidates[0][1]\n        else:\n            raise IOError('could not find class definition')\n    raise IOError('could not find code object')\n\n\ndef getblocks(object, lstrip=False, enclosing=False, locate=False):\n    \"\"\"Return a list of source lines and starting line number for an object.\n    Interactively-defined objects refer to lines in the interpreter's history.\n\n    If enclosing=True, then also return any enclosing code.\n    If lstrip=True, ensure there is no indentation in the first line of code.\n    If locate=True, then also return the line number for the block of code.\n\n    DEPRECATED: use 'getsourcelines' instead\n    \"\"\"\n    lines, lnum = findsource(object)\n\n    if ismodule(object):\n        if lstrip: lines = _outdent(lines)\n        return ([lines], [0]) if locate is True else [lines]\n\n    #XXX: 'enclosing' means: closures only? or classes and files?\n    indent = indentsize(lines[lnum])\n    block = getblock(lines[lnum:]) #XXX: catch any TokenError here?\n\n    if not enclosing or not indent:\n        if lstrip: block = _outdent(block)\n        return ([block], [lnum]) if locate is True else [block]\n\n    pat1 = r'^(\\s*def\\s)|(.*(?<!\\w)lambda(:|\\s))'; pat1 = re.compile(pat1)\n    pat2 = r'^(\\s*@)'; pat2 = re.compile(pat2)\n   #pat3 = r'^(\\s*class\\s)'; pat3 = re.compile(pat3) #XXX: enclosing class?\n    #FIXME: bound methods need enclosing class (and then instantiation)\n    #       *or* somehow apply a partial using the instance\n\n    skip = 0\n    line = 0\n    blocks = []; _lnum = []\n    target = ''.join(block)\n    while line <= lnum: #XXX: repeat lnum? or until line < lnum?\n        # see if starts with ('def','lambda') and contains our target block\n        if pat1.match(lines[line]):\n            if not skip:\n                try: code = getblock(lines[line:])\n                except TokenError: code = [lines[line]]\n            if indentsize(lines[line]) > indent: #XXX: should be >= ?\n                line += len(code) - skip\n            elif target in ''.join(code):\n                blocks.append(code) # save code block as the potential winner\n                _lnum.append(line - skip) # save the line number for the match\n                line += len(code) - skip\n            else:\n                line += 1\n            skip = 0\n        # find skip: the number of consecutive decorators\n        elif pat2.match(lines[line]):\n            try: code = getblock(lines[line:])\n            except TokenError: code = [lines[line]]\n            skip = 1\n            for _line in code[1:]: # skip lines that are decorators\n                if not pat2.match(_line): break\n                skip += 1\n            line += skip\n        # no match: reset skip and go to the next line\n        else:\n            line +=1\n            skip = 0\n\n    if not blocks:\n        blocks = [block]\n        _lnum = [lnum]\n    if lstrip: blocks = [_outdent(block) for block in blocks]\n    # return last match\n    return (blocks, _lnum) if locate is True else blocks\n\n\ndef getsourcelines(object, lstrip=False, enclosing=False):\n    \"\"\"Return a list of source lines and starting line number for an object.\n    Interactively-defined objects refer to lines in the interpreter's history.\n\n    The argument may be a module, class, method, function, traceback, frame,\n    or code object.  The source code is returned as a list of the lines\n    corresponding to the object and the line number indicates where in the\n    original source file the first line of code was found.  An IOError is\n    raised if the source code cannot be retrieved, while a TypeError is\n    raised for objects where the source code is unavailable (e.g. builtins).\n\n    If lstrip=True, ensure there is no indentation in the first line of code.\n    If enclosing=True, then also return any enclosing code.\"\"\"\n    code, n = getblocks(object, lstrip=lstrip, enclosing=enclosing, locate=True)\n    return code[-1], n[-1]\n\n\n#NOTE: broke backward compatibility 4/16/14 (was lstrip=True, force=True)\ndef getsource(object, alias='', lstrip=False, enclosing=False, \\\n                                              force=False, builtin=False):\n    \"\"\"Return the text of the source code for an object. The source code for\n    interactively-defined objects are extracted from the interpreter's history.\n\n    The argument may be a module, class, method, function, traceback, frame,\n    or code object.  The source code is returned as a single string.  An\n    IOError is raised if the source code cannot be retrieved, while a\n    TypeError is raised for objects where the source code is unavailable\n    (e.g. builtins).\n\n    If alias is provided, then add a line of code that renames the object.\n    If lstrip=True, ensure there is no indentation in the first line of code.\n    If enclosing=True, then also return any enclosing code.\n    If force=True, catch (TypeError,IOError) and try to use import hooks.\n    If builtin=True, force an import for any builtins\n    \"\"\"\n    # hascode denotes a callable\n    hascode = _hascode(object)\n    # is a class instance type (and not in builtins)\n    instance = _isinstance(object)\n\n    # get source lines; if fail, try to 'force' an import\n    try: # fails for builtins, and other assorted object types\n        lines, lnum = getsourcelines(object, enclosing=enclosing)\n    except (TypeError, IOError): # failed to get source, resort to import hooks\n        if not force: # don't try to get types that findsource can't get\n            raise\n        if not getmodule(object): # get things like 'None' and '1'\n            if not instance: return getimport(object, alias, builtin=builtin)\n            # special handling (numpy arrays, ...)\n            _import = getimport(object, builtin=builtin)\n            name = getname(object, force=True)\n            _alias = \"%s = \" % alias if alias else \"\"\n            if alias == name: _alias = \"\"\n            return _import+_alias+\"%s\\n\" % name\n        else: #FIXME: could use a good bit of cleanup, since using getimport...\n            if not instance: return getimport(object, alias, builtin=builtin)\n            # now we are dealing with an instance...\n            name = object.__class__.__name__\n            module = object.__module__\n            if module in ['builtins','__builtin__']:\n                return getimport(object, alias, builtin=builtin)\n            else: #FIXME: leverage getimport? use 'from module import name'?\n                lines, lnum = [\"%s = __import__('%s', fromlist=['%s']).%s\\n\" % (name,module,name,name)], 0\n                obj = eval(lines[0].lstrip(name + ' = '))\n                lines, lnum = getsourcelines(obj, enclosing=enclosing)\n\n    # strip leading indent (helps ensure can be imported)\n    if lstrip or alias:\n        lines = _outdent(lines)\n\n    # instantiate, if there's a nice repr  #XXX: BAD IDEA???\n    if instance: #and force: #XXX: move into findsource or getsourcelines ?\n        if '(' in repr(object): lines.append('%r\\n' % object)\n       #else: #XXX: better to somehow to leverage __reduce__ ?\n       #    reconstructor,args = object.__reduce__()\n       #    _ = reconstructor(*args)\n        else: # fall back to serialization #XXX: bad idea?\n            #XXX: better not duplicate work? #XXX: better new/enclose=True?\n            lines = dumpsource(object, alias='', new=force, enclose=False)\n            lines, lnum = [line+'\\n' for line in lines.split('\\n')][:-1], 0\n       #else: object.__code__ # raise AttributeError\n\n    # add an alias to the source code\n    if alias:\n        if hascode:\n            skip = 0\n            for line in lines: # skip lines that are decorators\n                if not line.startswith('@'): break\n                skip += 1\n            #XXX: use regex from findsource / getsourcelines ?\n            if lines[skip].lstrip().startswith('def '): # we have a function\n                if alias != object.__name__:\n                    lines.append('\\n%s = %s\\n' % (alias, object.__name__))\n            elif 'lambda ' in lines[skip]: # we have a lambda\n                if alias != lines[skip].split('=')[0].strip():\n                    lines[skip] = '%s = %s' % (alias, lines[skip])\n            else: # ...try to use the object's name\n                if alias != object.__name__:\n                    lines.append('\\n%s = %s\\n' % (alias, object.__name__))\n        else: # class or class instance\n            if instance:\n                if alias != lines[-1].split('=')[0].strip():\n                    lines[-1] = ('%s = ' % alias) + lines[-1]\n            else:\n                name = getname(object, force=True) or object.__name__\n                if alias != name:\n                    lines.append('\\n%s = %s\\n' % (alias, name))\n    return ''.join(lines)\n\n\ndef _hascode(object):\n    '''True if object has an attribute that stores it's __code__'''\n    return getattr(object,'__code__',None) or getattr(object,'func_code',None)\n\ndef _isinstance(object):\n    '''True if object is a class instance type (and is not a builtin)'''\n    if _hascode(object) or isclass(object) or ismodule(object):\n        return False\n    if istraceback(object) or isframe(object) or iscode(object):\n        return False\n    # special handling (numpy arrays, ...)\n    if not getmodule(object) and getmodule(type(object)).__name__ in ['numpy']:\n        return True\n#   # check if is instance of a builtin\n#   if not getmodule(object) and getmodule(type(object)).__name__ in ['__builtin__','builtins']:\n#       return False\n    _types = ('<class ',\"<type 'instance'>\")\n    if not repr(type(object)).startswith(_types): #FIXME: weak hack\n        return False\n    if not getmodule(object) or object.__module__ in ['builtins','__builtin__'] or getname(object, force=True) in ['array']:\n        return False\n    return True # by process of elimination... it's what we want\n\n\ndef _intypes(object):\n    '''check if object is in the 'types' module'''\n    import types\n    # allow user to pass in object or object.__name__\n    if type(object) is not type(''):\n        object = getname(object, force=True)\n    if object == 'ellipsis': object = 'EllipsisType'\n    return True if hasattr(types, object) else False\n\n\ndef _isstring(object): #XXX: isstringlike better?\n    '''check if object is a string-like type'''\n    if PY3: return isinstance(object, (str, bytes))\n    return isinstance(object, basestring)\n\n\ndef indent(code, spaces=4):\n    '''indent a block of code with whitespace (default is 4 spaces)'''\n    indent = indentsize(code) \n    if type(spaces) is int: spaces = ' '*spaces\n    # if '\\t' is provided, will indent with a tab\n    nspaces = indentsize(spaces)\n    # blank lines (etc) need to be ignored\n    lines = code.split('\\n')\n##  stq = \"'''\"; dtq = '\"\"\"'\n##  in_stq = in_dtq = False\n    for i in range(len(lines)):\n        #FIXME: works... but shouldn't indent 2nd+ lines of multiline doc\n        _indent = indentsize(lines[i])\n        if indent > _indent: continue\n        lines[i] = spaces+lines[i]\n##      #FIXME: may fail when stq and dtq in same line (depends on ordering)\n##      nstq, ndtq = lines[i].count(stq), lines[i].count(dtq)\n##      if not in_dtq and not in_stq:\n##          lines[i] = spaces+lines[i] # we indent\n##          # entering a comment block\n##          if nstq%2: in_stq = not in_stq\n##          if ndtq%2: in_dtq = not in_dtq\n##      # leaving a comment block\n##      elif in_dtq and ndtq%2: in_dtq = not in_dtq\n##      elif in_stq and nstq%2: in_stq = not in_stq\n##      else: pass\n    if lines[-1].strip() == '': lines[-1] = ''\n    return '\\n'.join(lines)\n\n\ndef _outdent(lines, spaces=None, all=True):\n    '''outdent lines of code, accounting for docs and line continuations'''\n    indent = indentsize(lines[0]) \n    if spaces is None or spaces > indent or spaces < 0: spaces = indent\n    for i in range(len(lines) if all else 1):\n        #FIXME: works... but shouldn't outdent 2nd+ lines of multiline doc\n        _indent = indentsize(lines[i])\n        if spaces > _indent: _spaces = _indent\n        else: _spaces = spaces\n        lines[i] = lines[i][_spaces:]\n    return lines\n\ndef outdent(code, spaces=None, all=True):\n    '''outdent a block of code (default is to strip all leading whitespace)'''\n    indent = indentsize(code) \n    if spaces is None or spaces > indent or spaces < 0: spaces = indent\n    #XXX: will this delete '\\n' in some cases?\n    if not all: return code[spaces:]\n    return '\\n'.join(_outdent(code.split('\\n'), spaces=spaces, all=all))\n\n\n#XXX: not sure what the point of _wrap is...\n#exec_ = lambda s, *a: eval(compile(s, '<string>', 'exec'), *a)\n__globals__ = globals()\n__locals__ = locals()\nwrap2 = '''\ndef _wrap(f):\n    \"\"\" encapsulate a function and it's __import__ \"\"\"\n    def func(*args, **kwds):\n        try:\n            # _ = eval(getsource(f, force=True)) #XXX: safer but less robust\n            exec getimportable(f, alias='_') in %s, %s\n        except:\n            raise ImportError('cannot import name ' + f.__name__)\n        return _(*args, **kwds)\n    func.__name__ = f.__name__\n    func.__doc__ = f.__doc__\n    return func\n''' % ('__globals__', '__locals__')\nwrap3 = '''\ndef _wrap(f):\n    \"\"\" encapsulate a function and it's __import__ \"\"\"\n    def func(*args, **kwds):\n        try:\n            # _ = eval(getsource(f, force=True)) #XXX: safer but less robust\n            exec(getimportable(f, alias='_'), %s, %s)\n        except:\n            raise ImportError('cannot import name ' + f.__name__)\n        return _(*args, **kwds)\n    func.__name__ = f.__name__\n    func.__doc__ = f.__doc__\n    return func\n''' % ('__globals__', '__locals__')\nif PY3:\n    exec(wrap3)\nelse:\n    exec(wrap2)\ndel wrap2, wrap3\n\n\ndef _enclose(object, alias=''): #FIXME: needs alias to hold returned object\n    \"\"\"create a function enclosure around the source of some object\"\"\"\n    #XXX: dummy and stub should append a random string\n    dummy = '__this_is_a_big_dummy_enclosing_function__'\n    stub = '__this_is_a_stub_variable__'\n    code = 'def %s():\\n' % dummy\n    code += indent(getsource(object, alias=stub, lstrip=True, force=True))\n    code += indent('return %s\\n' % stub)\n    if alias: code += '%s = ' % alias\n    code += '%s(); del %s\\n' % (dummy, dummy)\n   #code += \"globals().pop('%s',lambda :None)()\\n\" % dummy\n    return code\n\n\ndef dumpsource(object, alias='', new=False, enclose=True):\n    \"\"\"'dump to source', where the code includes a pickled object.\n\n    If new=True and object is a class instance, then create a new\n    instance using the unpacked class source code. If enclose, then\n    create the object inside a function enclosure (thus minimizing\n    any global namespace pollution).\n    \"\"\"\n    from dill import dumps\n    pik = repr(dumps(object))\n    code = 'import dill\\n'\n    if enclose:\n        stub = '__this_is_a_stub_variable__' #XXX: *must* be same _enclose.stub\n        pre = '%s = ' % stub\n        new = False #FIXME: new=True doesn't work with enclose=True\n    else:\n        stub = alias\n        pre = '%s = ' % stub if alias else alias\n    \n    # if a 'new' instance is not needed, then just dump and load\n    if not new or not _isinstance(object):\n        code += pre + 'dill.loads(%s)\\n' % pik\n    else: #XXX: other cases where source code is needed???\n        code += getsource(object.__class__, alias='', lstrip=True, force=True)\n        mod = repr(object.__module__) # should have a module (no builtins here)\n        if PY3:\n            code += pre + 'dill.loads(%s.replace(b%s,bytes(__name__,\"UTF-8\")))\\n' % (pik,mod)\n        else:\n            code += pre + 'dill.loads(%s.replace(%s,__name__))\\n' % (pik,mod)\n       #code += 'del %s' % object.__class__.__name__ #NOTE: kills any existing!\n\n    if enclose:\n        # generation of the 'enclosure'\n        dummy = '__this_is_a_big_dummy_object__'\n        dummy = _enclose(dummy, alias=alias)\n        # hack to replace the 'dummy' with the 'real' code\n        dummy = dummy.split('\\n')\n        code = dummy[0]+'\\n' + indent(code) + '\\n'.join(dummy[-3:])\n\n    return code #XXX: better 'dumpsourcelines', returning list of lines?\n\n\ndef getname(obj, force=False, fqn=False): #XXX: throw(?) to raise error on fail?\n    \"\"\"get the name of the object. for lambdas, get the name of the pointer \"\"\"\n    if fqn: return '.'.join(_namespace(obj))\n    module = getmodule(obj)\n    if not module: # things like \"None\" and \"1\"\n        if not force: return None\n        return repr(obj)\n    try:\n        #XXX: 'wrong' for decorators and curried functions ?\n        #       if obj.func_closure: ...use logic from getimportable, etc ?\n        name = obj.__name__\n        if name == '<lambda>':\n            return getsource(obj).split('=',1)[0].strip()\n        # handle some special cases\n        if module.__name__ in ['builtins','__builtin__']:\n            if name == 'ellipsis': name = 'EllipsisType'\n        return name\n    except AttributeError: #XXX: better to just throw AttributeError ?\n        if not force: return None\n        name = repr(obj)\n        if name.startswith('<'): # or name.split('('):\n            return None\n        return name\n\n\ndef _namespace(obj):\n    \"\"\"_namespace(obj); return namespace hierarchy (as a list of names)\n    for the given object.  For an instance, find the class hierarchy.\n\n    For example:\n\n    >>> from functools import partial\n    >>> p = partial(int, base=2)\n    >>> _namespace(p)\n    [\\'functools\\', \\'partial\\']\n    \"\"\"\n    # mostly for functions and modules and such\n    #FIXME: 'wrong' for decorators and curried functions\n    try: #XXX: needs some work and testing on different types\n        module = qual = str(getmodule(obj)).split()[1].strip('\"').strip(\"'\")\n        qual = qual.split('.')\n        if ismodule(obj):\n            return qual\n        # get name of a lambda, function, etc\n        name = getname(obj) or obj.__name__ # failing, raise AttributeError\n        # check special cases (NoneType, ...)\n        if module in ['builtins','__builtin__']: # BuiltinFunctionType\n            if _intypes(name): return ['types'] + [name]\n        return qual + [name] #XXX: can be wrong for some aliased objects\n    except: pass\n    # special case: numpy.inf and numpy.nan (we don't want them as floats)\n    if str(obj) in ['inf','nan','Inf','NaN']: # is more, but are they needed?\n        return ['numpy'] + [str(obj)]\n    # mostly for classes and class instances and such\n    module = getattr(obj.__class__, '__module__', None)\n    qual = str(obj.__class__)\n    try: qual = qual[qual.index(\"'\")+1:-2]\n    except ValueError: pass # str(obj.__class__) made the 'try' unnecessary\n    qual = qual.split(\".\")\n    if module in ['builtins','__builtin__']:\n        # check special cases (NoneType, Ellipsis, ...)\n        if qual[-1] == 'ellipsis': qual[-1] = 'EllipsisType'\n        if _intypes(qual[-1]): module = 'types' #XXX: BuiltinFunctionType\n        qual = [module] + qual\n    return qual\n\n\n#NOTE: 05/25/14 broke backward compatability: added 'alias' as 3rd argument\ndef _getimport(head, tail, alias='', verify=True, builtin=False):\n    \"\"\"helper to build a likely import string from head and tail of namespace.\n    ('head','tail') are used in the following context: \"from head import tail\"\n\n    If verify=True, then test the import string before returning it.\n    If builtin=True, then force an import for builtins where possible.\n    If alias is provided, then rename the object on import.\n    \"\"\"\n    # special handling for a few common types\n    if tail in ['Ellipsis', 'NotImplemented'] and head in ['types']:\n        head = len.__module__\n    elif tail in ['None'] and head in ['types']:\n        _alias = '%s = ' % alias if alias else ''\n        if alias == tail: _alias = ''\n        return _alias+'%s\\n' % tail\n    # we don't need to import from builtins, so return ''\n#   elif tail in ['NoneType','int','float','long','complex']: return '' #XXX: ?\n    if head in ['builtins','__builtin__']:\n        # special cases (NoneType, Ellipsis, ...) #XXX: BuiltinFunctionType\n        if tail == 'ellipsis': tail = 'EllipsisType'\n        if _intypes(tail): head = 'types'\n        elif not builtin:\n            _alias = '%s = ' % alias if alias else ''\n            if alias == tail: _alias = ''\n            return _alias+'%s\\n' % tail\n        else: pass # handle builtins below\n    # get likely import string\n    if not head: _str = \"import %s\" % tail\n    else: _str = \"from %s import %s\" % (head, tail)\n    _alias = \" as %s\\n\" % alias if alias else \"\\n\"\n    if alias == tail: _alias = \"\\n\"\n    _str += _alias\n    # FIXME: fails on most decorators, currying, and such...\n    #        (could look for magic __wrapped__ or __func__ attr)\n    #        (could fix in 'namespace' to check obj for closure)\n    if verify and not head.startswith('dill.'):# weird behavior for dill\n       #print(_str)\n        try: exec(_str) #XXX: check if == obj? (name collision)\n        except ImportError: #XXX: better top-down or bottom-up recursion?\n            _head = head.rsplit(\".\",1)[0] #(or get all, then compare == obj?)\n            if not _head: raise\n            if _head != head:\n                _str = _getimport(_head, tail, alias, verify)\n    return _str\n\n\n#XXX: rename builtin to force? vice versa? verify to force? (as in getsource)\n#NOTE: 05/25/14 broke backward compatability: added 'alias' as 2nd argument\ndef getimport(obj, alias='', verify=True, builtin=False, enclosing=False):\n    \"\"\"get the likely import string for the given object\n\n    obj is the object to inspect\n    If verify=True, then test the import string before returning it.\n    If builtin=True, then force an import for builtins where possible.\n    If enclosing=True, get the import for the outermost enclosing callable.\n    If alias is provided, then rename the object on import.\n    \"\"\"\n    if enclosing:\n        from .detect import outermost\n        _obj = outermost(obj)\n        obj = _obj if _obj else obj\n    # get the namespace\n    qual = _namespace(obj)\n    head = '.'.join(qual[:-1])\n    tail = qual[-1]\n    # for named things... with a nice repr #XXX: move into _namespace?\n    try: # look for '<...>' and be mindful it might be in lists, dicts, etc...\n        name = repr(obj).split('<',1)[1].split('>',1)[1]\n        name = None # we have a 'object'-style repr\n    except: # it's probably something 'importable'\n        if head in ['builtins','__builtin__']:\n            name = repr(obj) #XXX: catch [1,2], (1,2), set([1,2])... others?\n        else:\n            name = repr(obj).split('(')[0]\n   #if not repr(obj).startswith('<'): name = repr(obj).split('(')[0]\n   #else: name = None\n    if name: # try using name instead of tail\n        try: return _getimport(head, name, alias, verify, builtin)\n        except ImportError: pass\n        except SyntaxError:\n            if head in ['builtins','__builtin__']:\n                _alias = '%s = ' % alias if alias else ''\n                if alias == name: _alias = ''\n                return _alias+'%s\\n' % name\n            else: pass\n    try:\n       #if type(obj) is type(abs): _builtin = builtin # BuiltinFunctionType\n       #else: _builtin = False\n        return _getimport(head, tail, alias, verify, builtin)\n    except ImportError:\n        raise # could do some checking against obj\n    except SyntaxError:\n        if head in ['builtins','__builtin__']:\n            _alias = '%s = ' % alias if alias else ''\n            if alias == tail: _alias = ''\n            return _alias+'%s\\n' % tail\n        raise # could do some checking against obj\n\n\ndef _importable(obj, alias='', source=None, enclosing=False, force=True, \\\n                                              builtin=True, lstrip=True):\n    \"\"\"get an import string (or the source code) for the given object\n\n    This function will attempt to discover the name of the object, or the repr\n    of the object, or the source code for the object. To attempt to force\n    discovery of the source code, use source=True, to attempt to force the\n    use of an import, use source=False; otherwise an import will be sought\n    for objects not defined in __main__. The intent is to build a string\n    that can be imported from a python file. obj is the object to inspect.\n    If alias is provided, then rename the object with the given alias.\n\n    If source=True, use these options:\n      If enclosing=True, then also return any enclosing code.\n      If force=True, catch (TypeError,IOError) and try to use import hooks.\n      If lstrip=True, ensure there is no indentation in the first line of code.\n\n    If source=False, use these options:\n      If enclosing=True, get the import for the outermost enclosing callable.\n      If force=True, then don't test the import string before returning it.\n      If builtin=True, then force an import for builtins where possible.\n    \"\"\"\n    if source is None:\n        source = True if isfrommain(obj) else False\n    if source: # first try to get the source\n        try:\n            return getsource(obj, alias, enclosing=enclosing, \\\n                             force=force, lstrip=lstrip, builtin=builtin)\n        except: pass\n    try:\n        if not _isinstance(obj):\n            return getimport(obj, alias, enclosing=enclosing, \\\n                                  verify=(not force), builtin=builtin)\n        # first 'get the import', then 'get the instance'\n        _import = getimport(obj, enclosing=enclosing, \\\n                                 verify=(not force), builtin=builtin)\n        name = getname(obj, force=True)\n        if not name:\n            raise AttributeError(\"object has no atribute '__name__'\")\n        _alias = \"%s = \" % alias if alias else \"\"\n        if alias == name: _alias = \"\"\n        return _import+_alias+\"%s\\n\" % name\n\n    except: pass\n    if not source: # try getsource, only if it hasn't been tried yet\n        try:\n            return getsource(obj, alias, enclosing=enclosing, \\\n                             force=force, lstrip=lstrip, builtin=builtin)\n        except: pass\n    # get the name (of functions, lambdas, and classes)\n    # or hope that obj can be built from the __repr__\n    #XXX: what to do about class instances and such?\n    obj = getname(obj, force=force)\n    # we either have __repr__ or __name__ (or None)\n    if not obj or obj.startswith('<'):\n        raise AttributeError(\"object has no atribute '__name__'\")\n    _alias = '%s = ' % alias if alias else ''\n    if alias == obj: _alias = ''\n    return _alias+'%s\\n' % obj\n    #XXX: possible failsafe... (for example, for instances when source=False)\n    #     \"import dill; result = dill.loads(<pickled_object>); # repr(<object>)\"\n\ndef _closuredimport(func, alias='', builtin=False):\n    \"\"\"get import for closured objects; return a dict of 'name' and 'import'\"\"\"\n    import re\n    from .detect import freevars, outermost\n    free_vars = freevars(func)\n    func_vars = {}\n    # split into 'funcs' and 'non-funcs'\n    for name,obj in list(free_vars.items()):\n        if not isfunction(obj): continue\n        # get import for 'funcs'\n        fobj = free_vars.pop(name)\n        src = getsource(fobj)\n        if src.lstrip().startswith('@'): # we have a decorator\n            src = getimport(fobj, alias=alias, builtin=builtin)\n        else: # we have to \"hack\" a bit... and maybe be lucky\n            encl = outermost(func)\n            # pattern: 'func = enclosing(fobj'\n            pat = r'.*[\\w\\s]=\\s*'+getname(encl)+r'\\('+getname(fobj)\n            mod = getname(getmodule(encl))\n            #HACK: get file containing 'outer' function; is func there?\n            lines,_ = findsource(encl)\n            candidate = [line for line in lines if getname(encl) in line and \\\n                         re.match(pat, line)]\n            if not candidate:\n                mod = getname(getmodule(fobj))\n                #HACK: get file containing 'inner' function; is func there? \n                lines,_ = findsource(fobj)\n                candidate = [line for line in lines \\\n                             if getname(fobj) in line and re.match(pat, line)]\n            if not len(candidate): raise TypeError('import could not be found')\n            candidate = candidate[-1]\n            name = candidate.split('=',1)[0].split()[-1].strip()\n            src = _getimport(mod, name, alias=alias, builtin=builtin)\n        func_vars[name] = src\n    if not func_vars:\n        name = outermost(func)\n        mod = getname(getmodule(name))\n        if not mod or name is func: # then it can be handled by getimport\n            name = getname(func, force=True) #XXX: better key?\n            src = getimport(func, alias=alias, builtin=builtin)\n        else:\n            lines,_ = findsource(name)\n            # pattern: 'func = enclosing('\n            candidate = [line for line in lines if getname(name) in line and \\\n                         re.match(r'.*[\\w\\s]=\\s*'+getname(name)+r'\\(', line)]\n            if not len(candidate): raise TypeError('import could not be found')\n            candidate = candidate[-1]\n            name = candidate.split('=',1)[0].split()[-1].strip()\n            src = _getimport(mod, name, alias=alias, builtin=builtin)\n        func_vars[name] = src\n    return func_vars\n\n#XXX: should be able to use __qualname__\ndef _closuredsource(func, alias=''):\n    \"\"\"get source code for closured objects; return a dict of 'name'\n    and 'code blocks'\"\"\"\n    #FIXME: this entire function is a messy messy HACK\n    #      - pollutes global namespace\n    #      - fails if name of freevars are reused\n    #      - can unnecessarily duplicate function code\n    from .detect import freevars\n    free_vars = freevars(func)\n    func_vars = {}\n    # split into 'funcs' and 'non-funcs'\n    for name,obj in list(free_vars.items()):\n        if not isfunction(obj):\n            # get source for 'non-funcs'\n            free_vars[name] = getsource(obj, force=True, alias=name)\n            continue\n        # get source for 'funcs'\n        fobj = free_vars.pop(name)\n        src = getsource(fobj, alias) # DO NOT include dependencies\n        # if source doesn't start with '@', use name as the alias\n        if not src.lstrip().startswith('@'): #FIXME: 'enclose' in dummy;\n            src = importable(fobj,alias=name)#        wrong ref 'name'\n            org = getsource(func, alias, enclosing=False, lstrip=True)\n            src = (src, org) # undecorated first, then target\n        else: #NOTE: reproduces the code!\n            org = getsource(func, enclosing=True, lstrip=False)\n            src = importable(fobj, alias, source=True) # include dependencies\n            src = (org, src) # target first, then decorated\n        func_vars[name] = src\n    src = ''.join(free_vars.values())\n    if not func_vars: #FIXME: 'enclose' in dummy; wrong ref 'name'\n        org = getsource(func, alias, force=True, enclosing=False, lstrip=True)\n        src = (src, org) # variables first, then target\n    else:\n        src = (src, None) # just variables        (better '' instead of None?)\n    func_vars[None] = src\n    # FIXME: remove duplicates (however, order is important...)\n    return func_vars\n\ndef importable(obj, alias='', source=None, builtin=True):\n    \"\"\"get an importable string (i.e. source code or the import string)\n    for the given object, including any required objects from the enclosing\n    and global scope\n\n    This function will attempt to discover the name of the object, or the repr\n    of the object, or the source code for the object. To attempt to force\n    discovery of the source code, use source=True, to attempt to force the\n    use of an import, use source=False; otherwise an import will be sought\n    for objects not defined in __main__. The intent is to build a string\n    that can be imported from a python file.\n\n    obj is the object to inspect. If alias is provided, then rename the\n    object with the given alias. If builtin=True, then force an import for\n    builtins where possible.\n    \"\"\"\n    #NOTE: we always 'force', and 'lstrip' as necessary\n    #NOTE: for 'enclosing', use importable(outermost(obj))\n    if source is None:\n        source = True if isfrommain(obj) else False\n    elif builtin and isbuiltin(obj):\n        source = False\n    tried_source = tried_import = False\n    while True:\n        if not source: # we want an import\n            try:\n                if _isinstance(obj): # for instances, punt to _importable\n                    return _importable(obj, alias, source=False, builtin=builtin)\n                src = _closuredimport(obj, alias=alias, builtin=builtin)\n                if len(src) == 0:\n                    raise NotImplementedError('not implemented')\n                if len(src) > 1:\n                    raise NotImplementedError('not implemented')\n                return list(src.values())[0]\n            except:\n                if tried_source: raise\n                tried_import = True\n        # we want the source\n        try:\n            src = _closuredsource(obj, alias=alias)\n            if len(src) == 0:\n                raise NotImplementedError('not implemented')\n            # groan... an inline code stitcher\n            def _code_stitcher(block):\n                \"stitch together the strings in tuple 'block'\"\n                if block[0] and block[-1]: block = '\\n'.join(block)\n                elif block[0]: block = block[0]\n                elif block[-1]: block = block[-1]\n                else: block = ''\n                return block\n            # get free_vars first\n            _src = _code_stitcher(src.pop(None))\n            _src = [_src] if _src else []\n            # get func_vars\n            for xxx in src.values():\n                xxx = _code_stitcher(xxx)\n                if xxx: _src.append(xxx)\n            # make a single source string\n            if not len(_src):\n                src = ''\n            elif len(_src) == 1:\n                src = _src[0]\n            else:\n                src = '\\n'.join(_src)\n            # get source code of objects referred to by obj in global scope\n            from .detect import globalvars\n            obj = globalvars(obj) #XXX: don't worry about alias? recurse? etc?\n            obj = list(getsource(_obj,name,force=True) for (name,_obj) in obj.items() if not isbuiltin(_obj))\n            obj = '\\n'.join(obj) if obj else ''\n            # combine all referred-to source (global then enclosing)\n            if not obj: return src\n            if not src: return obj\n            return obj + src\n        except:\n            if tried_import: raise\n            tried_source = True\n            source = not source\n    # should never get here\n    return\n\n\n# backward compatability\ndef getimportable(obj, alias='', byname=True, explicit=False):\n    return importable(obj,alias,source=(not byname),builtin=explicit)\n   #return outdent(_importable(obj,alias,source=(not byname),builtin=explicit))\ndef likely_import(obj, passive=False, explicit=False):\n    return getimport(obj, verify=(not passive), builtin=explicit)\ndef _likely_import(first, last, passive=False, explicit=True):\n    return _getimport(first, last, verify=(not passive), builtin=explicit)\n_get_name = getname\ngetblocks_from_history = getblocks\n\n\n\n# EOF\n"
            },
            "temp": {
                "type": "module",
                "extension": "py",
                "code": "#!/usr/bin/env python\n#\n# Author: Mike McKerns (mmckerns @caltech and @uqfoundation)\n# Copyright (c) 2008-2016 California Institute of Technology.\n# Copyright (c) 2016-2020 The Uncertainty Quantification Foundation.\n# License: 3-clause BSD.  The full license text is available at:\n#  - https://github.com/uqfoundation/dill/blob/master/LICENSE\n\"\"\"\nMethods for serialized objects (or source code) stored in temporary files\nand file-like objects.\n\"\"\"\n#XXX: better instead to have functions write to any given file-like object ?\n#XXX: currently, all file-like objects are created by the function...\n\n__all__ = ['dump_source', 'dump', 'dumpIO_source', 'dumpIO',\\\n           'load_source', 'load', 'loadIO_source', 'loadIO',\\\n           'capture']\n\nimport contextlib\nfrom ._dill import PY3\n\n\n@contextlib.contextmanager\ndef capture(stream='stdout'):\n    \"\"\"builds a context that temporarily replaces the given stream name\n\n    >>> with capture('stdout') as out:\n    ...   print \"foo!\"\n    ... \n    >>> print out.getvalue()\n    foo!\n\n    \"\"\"\n    import sys\n    if PY3:\n        from io import StringIO\n    else:\n        from StringIO import StringIO\n    orig = getattr(sys, stream)\n    setattr(sys, stream, StringIO())\n    try:\n        yield getattr(sys, stream)\n    finally:\n        setattr(sys, stream, orig)\n\n\ndef b(x): # deal with b'foo' versus 'foo'\n    import codecs\n    return codecs.latin_1_encode(x)[0]\n\ndef load_source(file, **kwds):\n    \"\"\"load an object that was stored with dill.temp.dump_source\n\n    file: filehandle\n    alias: string name of stored object\n    mode: mode to open the file, one of: {'r', 'rb'}\n\n    >>> f = lambda x: x**2\n    >>> pyfile = dill.temp.dump_source(f, alias='_f')\n    >>> _f = dill.temp.load_source(pyfile)\n    >>> _f(4)\n    16\n    \"\"\"\n    alias = kwds.pop('alias', None)\n    mode = kwds.pop('mode', 'r')\n    fname = getattr(file, 'name', file) # fname=file.name or fname=file (if str)\n    source = open(fname, mode=mode, **kwds).read()\n    if not alias:\n        tag = source.strip().splitlines()[-1].split()\n        if tag[0] != '#NAME:':\n            stub = source.splitlines()[0]\n            raise IOError(\"unknown name for code: %s\" % stub)\n        alias = tag[-1]\n    local = {}\n    exec(source, local)\n    _ = eval(\"%s\" % alias, local)\n    return _\n\ndef dump_source(object, **kwds):\n    \"\"\"write object source to a NamedTemporaryFile (instead of dill.dump)\nLoads with \"import\" or \"dill.temp.load_source\".  Returns the filehandle.\n\n    >>> f = lambda x: x**2\n    >>> pyfile = dill.temp.dump_source(f, alias='_f')\n    >>> _f = dill.temp.load_source(pyfile)\n    >>> _f(4)\n    16\n\n    >>> f = lambda x: x**2\n    >>> pyfile = dill.temp.dump_source(f, dir='.')\n    >>> modulename = os.path.basename(pyfile.name).split('.py')[0]\n    >>> exec('from %s import f as _f' % modulename)\n    >>> _f(4)\n    16\n\nOptional kwds:\n    If 'alias' is specified, the object will be renamed to the given string.\n\n    If 'prefix' is specified, the file name will begin with that prefix,\n    otherwise a default prefix is used.\n    \n    If 'dir' is specified, the file will be created in that directory,\n    otherwise a default directory is used.\n    \n    If 'text' is specified and true, the file is opened in text\n    mode.  Else (the default) the file is opened in binary mode.  On\n    some operating systems, this makes no difference.\n\nNOTE: Keep the return value for as long as you want your file to exist !\n    \"\"\" #XXX: write a \"load_source\"?\n    from .source import importable, getname\n    import tempfile\n    kwds.pop('suffix', '') # this is *always* '.py'\n    alias = kwds.pop('alias', '') #XXX: include an alias so a name is known\n    name = str(alias) or getname(object)\n    name = \"\\n#NAME: %s\\n\" % name\n    #XXX: assumes kwds['dir'] is writable and on $PYTHONPATH\n    file = tempfile.NamedTemporaryFile(suffix='.py', **kwds)\n    file.write(b(''.join([importable(object, alias=alias),name])))\n    file.flush()\n    return file\n\ndef load(file, **kwds):\n    \"\"\"load an object that was stored with dill.temp.dump\n\n    file: filehandle\n    mode: mode to open the file, one of: {'r', 'rb'}\n\n    >>> dumpfile = dill.temp.dump([1, 2, 3, 4, 5])\n    >>> dill.temp.load(dumpfile)\n    [1, 2, 3, 4, 5]\n    \"\"\"\n    import dill as pickle\n    mode = kwds.pop('mode', 'rb')\n    name = getattr(file, 'name', file) # name=file.name or name=file (if str)\n    return pickle.load(open(name, mode=mode, **kwds))\n\ndef dump(object, **kwds):\n    \"\"\"dill.dump of object to a NamedTemporaryFile.\nLoads with \"dill.temp.load\".  Returns the filehandle.\n\n    >>> dumpfile = dill.temp.dump([1, 2, 3, 4, 5])\n    >>> dill.temp.load(dumpfile)\n    [1, 2, 3, 4, 5]\n\nOptional kwds:\n    If 'suffix' is specified, the file name will end with that suffix,\n    otherwise there will be no suffix.\n    \n    If 'prefix' is specified, the file name will begin with that prefix,\n    otherwise a default prefix is used.\n    \n    If 'dir' is specified, the file will be created in that directory,\n    otherwise a default directory is used.\n    \n    If 'text' is specified and true, the file is opened in text\n    mode.  Else (the default) the file is opened in binary mode.  On\n    some operating systems, this makes no difference.\n\nNOTE: Keep the return value for as long as you want your file to exist !\n    \"\"\"\n    import dill as pickle\n    import tempfile\n    file = tempfile.NamedTemporaryFile(**kwds)\n    pickle.dump(object, file)\n    file.flush()\n    return file\n\ndef loadIO(buffer, **kwds):\n    \"\"\"load an object that was stored with dill.temp.dumpIO\n\n    buffer: buffer object\n\n    >>> dumpfile = dill.temp.dumpIO([1, 2, 3, 4, 5])\n    >>> dill.temp.loadIO(dumpfile)\n    [1, 2, 3, 4, 5]\n    \"\"\"\n    import dill as pickle\n    if PY3:\n        from io import BytesIO as StringIO\n    else:\n        from StringIO import StringIO\n    value = getattr(buffer, 'getvalue', buffer) # value or buffer.getvalue\n    if value != buffer: value = value() # buffer.getvalue()\n    return pickle.load(StringIO(value))\n\ndef dumpIO(object, **kwds):\n    \"\"\"dill.dump of object to a buffer.\nLoads with \"dill.temp.loadIO\".  Returns the buffer object.\n\n    >>> dumpfile = dill.temp.dumpIO([1, 2, 3, 4, 5])\n    >>> dill.temp.loadIO(dumpfile)\n    [1, 2, 3, 4, 5]\n    \"\"\"\n    import dill as pickle\n    if PY3:\n        from io import BytesIO as StringIO\n    else:\n        from StringIO import StringIO\n    file = StringIO()\n    pickle.dump(object, file)\n    file.flush()\n    return file\n\ndef loadIO_source(buffer, **kwds):\n    \"\"\"load an object that was stored with dill.temp.dumpIO_source\n\n    buffer: buffer object\n    alias: string name of stored object\n\n    >>> f = lambda x:x**2\n    >>> pyfile = dill.temp.dumpIO_source(f, alias='_f')\n    >>> _f = dill.temp.loadIO_source(pyfile)\n    >>> _f(4)\n    16\n    \"\"\"\n    alias = kwds.pop('alias', None)\n    source = getattr(buffer, 'getvalue', buffer) # source or buffer.getvalue\n    if source != buffer: source = source() # buffer.getvalue()\n    if PY3: source = source.decode() # buffer to string\n    if not alias:\n        tag = source.strip().splitlines()[-1].split()\n        if tag[0] != '#NAME:':\n            stub = source.splitlines()[0]\n            raise IOError(\"unknown name for code: %s\" % stub)\n        alias = tag[-1]\n    local = {}\n    exec(source, local)\n    _ = eval(\"%s\" % alias, local)\n    return _\n\ndef dumpIO_source(object, **kwds):\n    \"\"\"write object source to a buffer (instead of dill.dump)\nLoads by with dill.temp.loadIO_source.  Returns the buffer object.\n\n    >>> f = lambda x:x**2\n    >>> pyfile = dill.temp.dumpIO_source(f, alias='_f')\n    >>> _f = dill.temp.loadIO_source(pyfile)\n    >>> _f(4)\n    16\n\nOptional kwds:\n    If 'alias' is specified, the object will be renamed to the given string.\n    \"\"\"\n    from .source import importable, getname\n    if PY3:\n        from io import BytesIO as StringIO\n    else:\n        from StringIO import StringIO\n    alias = kwds.pop('alias', '') #XXX: include an alias so a name is known\n    name = str(alias) or getname(object)\n    name = \"\\n#NAME: %s\\n\" % name\n    #XXX: assumes kwds['dir'] is writable and on $PYTHONPATH\n    file = StringIO()\n    file.write(b(''.join([importable(object, alias=alias),name])))\n    file.flush()\n    return file\n\n\ndel contextlib\n\n\n# EOF\n"
            }
        }
    }
}
